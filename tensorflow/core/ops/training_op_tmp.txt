REGISTER_OP("ApplyPSGLD")
    .Input("var: Ref(T)")
    .Input("ms: Ref(T)")
    .Input("mom: Ref(T)")
    .Input("rnd: Ref(T)")
    .Input("lr: T")
    .Input("decay: T")
	.Input("momentum: T")
    .Input("epsilon: T")
    .Input("grad: T")
    .Output("out: Ref(T)")
    .Attr("T: numbertype")
    .Attr("use_locking: bool = false")
    .Doc(R"doc(
Update '*var' according to the PSGLD algorithm.
Note that in dense implement of this algorithm, ms and mom will 
update even if the grad is zero.

mean_square = decay * mean_square + (1-decay) * gradient ** 2
PCDer = epsilon + sqrt(mean_square)
Delta = momentum * Delta + learning_rate * gradient / PCDer
		+ sqrt(2 * learning_rate / PCDer) * randn(0, 1)

ms <- decay * ms_{t-1} + (1-decay) * grad * grad
pcder <- epsilon + sqrt(ms)
mom <- momentum * mom + lr * grad / pcder + sqrt(2 * lr / pcder) * randn(size(var))
var <- var - mom

var: Should be from a Variable().
ms: Should be from a Variable().
mom: Should be from a Variable().
rnd: Normal random noise. Should be from a Variable().
lr: Scaling factor. Must be a scalar.
epsilon: Ridge term. Must be a scalar.
decay: Decay rate. Must be a scalar.
grad: The gradient.
out: Same as "var".
use_locking: If `True`, updating of the var, m, and v tensors will be protected
  by a lock; otherwise the behavior is undefined, but may exhibit less
  contention.
)doc");

// sparse implement

REGISTER_OP("SparseApplyPSGLD")
    .Input("var: Ref(T)")
    .Input("ms: Ref(T)")
    .Input("mom: Ref(T)")
    .Input("rnd: Ref(T)")
    .Input("lr: T")
    .Input("decay: T")
    .Input("momentum: T")
    .Input("epsilon: T")
    .Input("grad: T")
    .Input("indices: Tindices")
    .Output("out: Ref(T)")
    .Attr("T: numbertype")
    .Attr("Tindices: {int32, int64}")
    .Attr("use_locking: bool = false")
    .Doc(R"doc(
Update '*var' according to the PSGLD algorithm, ms and mom will 
update even if the grad is zero, but in this sparse implement, ms 
and mom will not update in iterations the grad is zero.

mean_square = decay * mean_square + (1-decay) * gradient ** 2
PCDer = epsilon + sqrt(mean_square)
Delta = momentum * Delta + learning_rate * gradient / PCDer
		+ sqrt(2 * learning_rate / PCDer) * randn(0, 1)

ms <- decay * ms_{t-1} + (1-decay) * grad * grad
pcder <- epsilon + sqrt(ms)
mom <- momentum * mom + lr * grad / pcder + sqrt(2 * lr / pcder) * randn(size(var))
var <- var - mom

var: Should be from a Variable().
ms: Should be from a Variable().
mom: Should be from a Variable().
rnd: Normal random noise. Should be from a Variable().
lr: Scaling factor. Must be a scalar.
epsilon: Ridge term. Must be a scalar.
decay: Decay rate. Must be a scalar.
grad: The gradient.
indices: A vector of indices into the first dimension of var, ms and mom.
out: Same as "var".
use_locking: If `True`, updating of the var, m, and v tensors will be protected
  by a lock; otherwise the behavior is undefined, but may exhibit less
  contention.
)doc");
