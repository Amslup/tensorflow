syntax = "proto3";

package tensorflow.tensorforest;
option cc_enable_arenas = true;
option java_outer_classname = "TensorForestProtos";
option java_multiple_files = true;
option java_package = "org.tensorflow.framework";


// Represents a single value of any type, e.g. 5 or "abc".
message Value {
  oneof value {
    float float_value = 1;
    double double_value = 2;
    int32 int32_value = 3;
    int64 int64_value = 4;
    google.protobuf.Any custom_value = 5;
  }
};

message SparseVector {
  map<int64, Value> sparse_value = 1;
}

message Vector {
  repeated Value value = 1;
}


message Leaf {
  oneof leaf {
    // The interpretation of the values held in the leaves of a decision tree
    // is application specific, but some common cases are:
    // 1) len(vector) = 1, and the floating point value[0] holds the class 0
    //    probability in a two class classification problem.
    // 2) len(vector) = 1, and the integer value[0] holds the class prediction.
    // 3) The floating point value[i] holds the class i probability prediction.
    // 4) The floating point value[i] holds the i-th component of the
    //    vector prediction in a regression problem.
    // 5) sparse_vector holds the sparse class predictions for a classification
    //    problem with a large number of classes.
    Vector vector = 1;
    SparseVector sparse_vector = 2;
  }
  // For non-standard handling of leaves.
  repeated google.protobuf.Any additional_data = 3;
}

message FeatureId {
  google.protobuf.StringValue id = 1;
  repeated google.protobuf.Any additional_data = 2;
};

message ObliqueFeatures {
  // total value is sum(features[i] * weights[i]).
  repeated FeatureId features = 1;
  repeated float weights = 2;
}


message InequalityTest {
  // When the feature is missing, the test's outcome is undefined.
  oneof FeatureSum {
    FeatureId feature_id = 1;
    ObliqueFeatures oblique = 4;
  }
  enum Type {
    LESS_OR_EQUAL = 0;
    LESS_THAN = 1;
    GREATER_OR_EQUAL = 2;
    GREATER_THAN = 3;
  };
  Type type = 2;
  Value threshold = 3;
}

message BinaryNode {
  google.protobuf.Int32Value left_child_id = 1;
  google.protobuf.Int32Value right_child_id = 2;
  enum Direction {
    LEFT = 0;
    RIGHT = 1;
  }
  // When left_child_test is undefined for a particular datapoint (e.g. because
  // it's not defined when feature value is missing), the datapoint should go
  // in this direction.
  Direction default_direction = 3;
  // When a datapoint satisfies the test, it should be propagated to the left
  // child.
  oneof left_child_test {
    InequalityTest inequality_left_child_test = 4;
    google.protobuf.Any custom_left_child_test = 5;
  }
}


message TreeNode {
  // Following fields are provided for convenience and better readability.
  // Filling them in is not required.
  google.protobuf.Int32Value node_id = 1;
  google.protobuf.Int32Value depth = 2;
  google.protobuf.Int32Value subtree_size = 3;

  oneof node_type {
    BinaryNode binary_node = 4;
    Leaf leaf = 5;
    google.protobuf.Any custom_node_type = 6;
  }

  repeated google.protobuf.Any additional_data = 7;
}

// Proto used for tracking tree paths during inference time.
message TreePath {
  // Nodes are listed in order that they were traversed. i.e. nodes_visited[0]
  // is the tree's root node.
  repeated TreeNode nodes_visited = 1;
}

message DecisionTree {
  repeated TreeNode nodes = 1;
  repeated google.protobuf.Any additional_data = 2;
}

message GiniStats {
  // This allows us to quickly track and calculate impurity (classification)
  //  by storing the sum of input weights and the sum of the squares of the
  // input weights.  Weighted gini is then: 1 - (square / sum * sum).
  // Updates to these numbers are:
  //   old_i = leaf->value(label)
  //   new_i = old_i + incoming_weight
  //   sum -> sum + incoming_weight
  //   square -> square - (old_i ^ 2) + (new_i ^ 2)
  //   total_left_sum -> total_left_sum - old_left_i * old_total_i +
  //                                      new_left_i * new_total_i
  float square = 2;
}

message LeafStat {
  // The sum of the weights of the training examples that we have seen.
  // This is here, outside of the leaf_stat oneof, because almost all
  // types will want it.
  float weight_sum = 3;

  message GiniImpurityClassificationStats {
    oneof counts {
      Vector dense_counts = 1;
      SparseVector sparse_counts = 2;
    }
    GiniStats gini = 3;
  }

  // This is the info needed for calculating variance for regression.
  // Variance will still have to be summed over every output, but the
  // number of outputs in regression problems is almost always 1.
  message LeastSquaresRegressionStats {
    Vector mean_output = 1;
    Vector mean_output_squares = 2;
  }

  oneof leaf_stat {
    GiniImpurityClassificationStats classification = 1;
    LeastSquaresRegressionStats regression = 2;
  }
}

message SplitCandidate {
  // proto representing the potential node.
  BinaryNode split = 1;

  // Right counts are inferred from FertileSlot.leaf_stats and left.
  LeafStat left_stats = 4;

  // Right stats (not full counts) are kept here.
  LeafStat right_stats = 5;

  // Fields used when training with a graph runner.
  string unique_id = 6;
}

message FertileSlot {
  // The statistics for *all* the examples seen at this leaf.
  LeafStat leaf_stats = 4;

  repeated SplitCandidate candidates = 1;

  // The statistics for the examples seen at this leaf after all the
  // splits have been initialized.  If post_init_leaf_stats.weight_sum
  // is > 0, then all candidates have been initialized.  We need to track
  // both leaf_stats and post_init_leaf_stats because the first is used
  // to create the decision_tree::Leaf and the second is used to infer
  // the statistics for the right side of a split (given the leaf side
  // stats).
  LeafStat post_init_leaf_stats = 6;

  int32 node_id = 5;
  int32 depth = 7;
}

message FertileStats {
  // Tracks stats for each node.  node_to_slot[i] is the FertileSlot for node i.
  // This may be sized to max_nodes initially, or grow dynamically as needed.
  repeated FertileSlot node_to_slot = 1;
}

// A generic handle for any type of model.
message Model {
  oneof model {
    DecisionTree decision_tree = 1;
    Ensemble ensemble = 2;
    google.protobuf.Any custom_model = 3;
  }
  repeated google.protobuf.Any additional_data = 4;
}
