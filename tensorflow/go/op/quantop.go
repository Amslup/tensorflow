// Copyright 2017 The TensorFlow Authors. All Rights Reserved.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// DO NOT EDIT
// This file was machine generated by github.com/ctava/tensorflow/tensorflow/go/genop/wrap
//
// WARNING: This generation of wrapper function for TensorFlow ops is in an
// experimental state. The generated API can change without notice.

package op

import tf "github.com/tensorflow/tensorflow/tensorflow/go"

// Quantized Batch normalization.
//
// This op is deprecated and will be removed in the future. Prefer
// `tf.nn.batch_normalization`.
//
// Arguments:
//	t: A 4D input Tensor.
//	t_min: The value represented by the lowest quantized input.
//	t_max: The value represented by the highest quantized input.
//	m: A 1D mean Tensor with size matching the last dimension of t.
// This is the first output from tf.nn.moments,
// or a saved moving average thereof.
//	m_min: The value represented by the lowest quantized mean.
//	m_max: The value represented by the highest quantized mean.
//	v: A 1D variance Tensor with size matching the last dimension of t.
// This is the second output from tf.nn.moments,
// or a saved moving average thereof.
//	v_min: The value represented by the lowest quantized variance.
//	v_max: The value represented by the highest quantized variance.
//	beta: A 1D beta Tensor with size matching the last dimension of t.
// An offset to be added to the normalized tensor.
//	beta_min: The value represented by the lowest quantized offset.
//	beta_max: The value represented by the highest quantized offset.
//	gamma: A 1D gamma Tensor with size matching the last dimension of t.
// If "scale_after_normalization" is true, this tensor will be multiplied
// with the normalized tensor.
//	gamma_min: The value represented by the lowest quantized gamma.
//	gamma_max: The value represented by the highest quantized gamma.
//	
//	variance_epsilon: A small float number to avoid dividing by 0.
//	scale_after_normalization: A bool indicating whether the resulted tensor
// needs to be multiplied with gamma.
func QuantizedBatchNormWithGlobalNormalization(scope *Scope, t tf.Output, t_min tf.Output, t_max tf.Output, m tf.Output, m_min tf.Output, m_max tf.Output, v tf.Output, v_min tf.Output, v_max tf.Output, beta tf.Output, beta_min tf.Output, beta_max tf.Output, gamma tf.Output, gamma_min tf.Output, gamma_max tf.Output, out_type tf.DataType, variance_epsilon float32, scale_after_normalization bool)(result tf.Output, result_min tf.Output, result_max tf.Output) {
	if scope.Err() != nil {
		return
	}
	attrs := map[string]interface{}{"out_type": out_type,"variance_epsilon": variance_epsilon,"scale_after_normalization": scale_after_normalization,}
	opspec := tf.OpSpec{
		Type: "QuantizedBatchNormWithGlobalNormalization",
		Input: []tf.Input{
			t, t_min, t_max, m, m_min, m_max, v, v_min, v_max, beta, beta_min, beta_max, gamma, gamma_min, gamma_max, 
		},
		Attrs: attrs,
	}
	op := scope.AddOperation(opspec)
	return op.Output(0), op.Output(1), op.Output(2)
}

// QuantizedRelu6Attr is an optional argument to QuantizedRelu6.
type QuantizedRelu6Attr func(optionalAttr)


// QuantizedRelu6OutType sets the optional out_type attribute to value.
// If not specified, defaults to DT_QUINT8 
func QuantizedRelu6OutType(value tf.DataType) QuantizedRelu6Attr {
	return func(m optionalAttr) {
		m["out_type"] = value
	}
}

// Computes Quantized Rectified Linear 6: `min(max(features, 0), 6)`
//
// Arguments:
//	
//	min_features: The float value that the lowest quantized value represents.
//	max_features: The float value that the highest quantized value represents.
//
// Returns Has the same output shape as "features".The float value that the lowest quantized value represents.The float value that the highest quantized value represents.
func QuantizedRelu6(scope *Scope, features tf.Output, min_features tf.Output, max_features tf.Output, optional ...QuantizedRelu6Attr)(activations tf.Output, min_activations tf.Output, max_activations tf.Output) {
	if scope.Err() != nil {
		return
	}
	attrs := map[string]interface{}{}
	for _, a := range optional {
		a(attrs)
	}
	opspec := tf.OpSpec{
		Type: "QuantizedRelu6",
		Input: []tf.Input{
			features, min_features, max_features, 
		},
		Attrs: attrs,
	}
	op := scope.AddOperation(opspec)
	return op.Output(0), op.Output(1), op.Output(2)
}

// Given a quantized tensor described by (input, input_min, input_max), outputs a
//
// range that covers the actual values present in that tensor.  This op is
// typically used to produce the requested_output_min and requested_output_max for
// Requantize.
//
// Arguments:
//	
//	input_min: The float value that the minimum quantized input value represents.
//	input_max: The float value that the maximum quantized input value represents.
//
// Returns The computed min output.the computed max output.
func RequantizationRange(scope *Scope, input tf.Output, input_min tf.Output, input_max tf.Output)(output_min tf.Output, output_max tf.Output) {
	if scope.Err() != nil {
		return
	}
	opspec := tf.OpSpec{
		Type: "RequantizationRange",
		Input: []tf.Input{
			input, input_min, input_max, 
		},
	}
	op := scope.AddOperation(opspec)
	return op.Output(0), op.Output(1)
}

// Convert the quantized 'input' tensor into a lower-precision 'output', using the
//
// actual distribution of the values to maximize the usage of the lower bit depth
// and adjusting the output min and max ranges accordingly.
// 
// [input_min, input_max] are scalar floats that specify the range for the float
// interpretation of the 'input' data. For example, if input_min is -1.0f and
// input_max is 1.0f, and we are dealing with quint16 quantized data, then a 0
// value in the 16-bit data should be interpreted as -1.0f, and a 65535 means 1.0f.
// 
// This operator tries to squeeze as much precision as possible into an output with
// a lower bit depth by calculating the actual min and max values found in the
// data. For example, maybe that quint16 input has no values lower than 16,384 and
// none higher than 49,152. That means only half the range is actually needed, all
// the float interpretations are between -0.5f and 0.5f, so if we want to compress
// the data into a quint8 output, we can use that range rather than the theoretical
// -1.0f to 1.0f that is suggested by the input min and max.
// 
// In practice, this is most useful for taking output from operations like
// QuantizedMatMul that can produce higher bit-depth outputs than their inputs and
// may have large potential output ranges, but in practice have a distribution of
// input values that only uses a small fraction of the possible range. By feeding
// that output into this operator, we can reduce it from 32 bits down to 8 with
// minimal loss of accuracy.
//
// Arguments:
//	
//	input_min: The float value that the minimum quantized input value represents.
//	input_max: The float value that the maximum quantized input value represents.
//	out_type: The type of the output. Should be a lower bit depth than Tinput.
//
// Returns The float value that the minimum quantized output value represents.The float value that the maximum quantized output value represents.
func QuantizeDownAndShrinkRange(scope *Scope, input tf.Output, input_min tf.Output, input_max tf.Output, out_type tf.DataType)(output tf.Output, output_min tf.Output, output_max tf.Output) {
	if scope.Err() != nil {
		return
	}
	attrs := map[string]interface{}{"out_type": out_type,}
	opspec := tf.OpSpec{
		Type: "QuantizeDownAndShrinkRange",
		Input: []tf.Input{
			input, input_min, input_max, 
		},
		Attrs: attrs,
	}
	op := scope.AddOperation(opspec)
	return op.Output(0), op.Output(1), op.Output(2)
}

// QuantizedMatMulAttr is an optional argument to QuantizedMatMul.
type QuantizedMatMulAttr func(optionalAttr)


// QuantizedMatMulToutput sets the optional Toutput attribute to value.
// If not specified, defaults to DT_QINT32 
func QuantizedMatMulToutput(value tf.DataType) QuantizedMatMulAttr {
	return func(m optionalAttr) {
		m["Toutput"] = value
	}
}

// QuantizedMatMulTransposeA sets the optional transpose_a attribute to value.
//
// value: If true, `a` is transposed before multiplication.
// If not specified, defaults to false 
func QuantizedMatMulTransposeA(value bool) QuantizedMatMulAttr {
	return func(m optionalAttr) {
		m["transpose_a"] = value
	}
}

// QuantizedMatMulTransposeB sets the optional transpose_b attribute to value.
//
// value: If true, `b` is transposed before multiplication.
// If not specified, defaults to false 
func QuantizedMatMulTransposeB(value bool) QuantizedMatMulAttr {
	return func(m optionalAttr) {
		m["transpose_b"] = value
	}
}

// QuantizedMatMulTactivation sets the optional Tactivation attribute to value.
//
// value: The type of output produced by activation function
// following this operation.
// If not specified, defaults to DT_QUINT8 
func QuantizedMatMulTactivation(value tf.DataType) QuantizedMatMulAttr {
	return func(m optionalAttr) {
		m["Tactivation"] = value
	}
}

// Perform a quantized matrix multiplication of  `a` by the matrix `b`.
//
// The inputs must be two-dimensional matrices and the inner dimension of
// `a` (after being transposed if `transpose_a` is non-zero) must match the
// outer dimension of `b` (after being transposed if `transposed_b` is
// non-zero).
//
// Arguments:
//	a: Must be a two-dimensional tensor.
//	b: Must be a two-dimensional tensor.
//	min_a: The float value that the lowest quantized `a` value represents.
//	max_a: The float value that the highest quantized `a` value represents.
//	min_b: The float value that the lowest quantized `b` value represents.
//	max_b: The float value that the highest quantized `b` value represents.
//
// Returns The float value that the lowest quantized output value represents.The float value that the highest quantized output value represents.
func QuantizedMatMul(scope *Scope, a tf.Output, b tf.Output, min_a tf.Output, max_a tf.Output, min_b tf.Output, max_b tf.Output, optional ...QuantizedMatMulAttr)(out tf.Output, min_out tf.Output, max_out tf.Output) {
	if scope.Err() != nil {
		return
	}
	attrs := map[string]interface{}{}
	for _, a := range optional {
		a(attrs)
	}
	opspec := tf.OpSpec{
		Type: "QuantizedMatMul",
		Input: []tf.Input{
			a, b, min_a, max_a, min_b, max_b, 
		},
		Attrs: attrs,
	}
	op := scope.AddOperation(opspec)
	return op.Output(0), op.Output(1), op.Output(2)
}

// Convert the quantized 'input' tensor into a lower-precision 'output', using the
//
// output range specified with 'requested_output_min' and 'requested_output_max'.
// 
// [input_min, input_max] are scalar floats that specify the range for the float
// interpretation of the 'input' data. For example, if input_min is -1.0f and
// input_max is 1.0f, and we are dealing with quint16 quantized data, then a 0
// value in the 16-bit data should be interpreted as -1.0f, and a 65535 means 1.0f.
//
// Arguments:
//	
//	input_min: The float value that the minimum quantized input value represents.
//	input_max: The float value that the maximum quantized input value represents.
//	requested_output_min: The float value that the minimum quantized output value represents.
//	requested_output_max: The float value that the maximum quantized output value represents.
//	out_type: The type of the output. Should be a lower bit depth than Tinput.
//
// Returns The requested_output_min value is copied into this output.The requested_output_max value is copied into this output.
func Requantize(scope *Scope, input tf.Output, input_min tf.Output, input_max tf.Output, requested_output_min tf.Output, requested_output_max tf.Output, out_type tf.DataType)(output tf.Output, output_min tf.Output, output_max tf.Output) {
	if scope.Err() != nil {
		return
	}
	attrs := map[string]interface{}{"out_type": out_type,}
	opspec := tf.OpSpec{
		Type: "Requantize",
		Input: []tf.Input{
			input, input_min, input_max, requested_output_min, requested_output_max, 
		},
		Attrs: attrs,
	}
	op := scope.AddOperation(opspec)
	return op.Output(0), op.Output(1), op.Output(2)
}

// Compute gradients for a FakeQuantWithMinMaxVarsPerChannel operation.
//
// Arguments:
//	gradients: Backpropagated gradients above the FakeQuantWithMinMaxVars operation,
// shape one of: `[d]`, `[b, d]`,  `[b, h, w, d]`.
//	inputs: Values passed as inputs to the FakeQuantWithMinMaxVars operation, shape
//   same as `gradients`.
// min, max: Quantization interval, floats of shape `[d]`.
//	
//	
//
// Returns Backpropagated gradients w.r.t. inputs, shape same as
// `inputs`:
//   `gradients * (inputs >= min && inputs <= max)`.Backpropagated gradients w.r.t. min parameter, shape `[d]`:
// `sum_per_d(gradients * (inputs < min))`.Backpropagated gradients w.r.t. max parameter, shape `[d]`:
// `sum_per_d(gradients * (inputs > max))`.
func FakeQuantWithMinMaxVarsPerChannelGradient(scope *Scope, gradients tf.Output, inputs tf.Output, min tf.Output, max tf.Output)(backprops_wrt_input tf.Output, backprop_wrt_min tf.Output, backprop_wrt_max tf.Output) {
	if scope.Err() != nil {
		return
	}
	opspec := tf.OpSpec{
		Type: "FakeQuantWithMinMaxVarsPerChannelGradient",
		Input: []tf.Input{
			gradients, inputs, min, max, 
		},
	}
	op := scope.AddOperation(opspec)
	return op.Output(0), op.Output(1), op.Output(2)
}

// Fake-quantize the 'inputs' tensor of type float and one of the shapes: `[d]`,
//
// `[b, d]` `[b, h, w, d]` via per-channel floats `min` and `max` of shape `[d]`
// to 'outputs' tensor of same shape as `inputs`.
// 
// [min; max] is the clamping range for the 'inputs' data in the corresponding
// depth channel.  Op divides this range into 255 steps (total of 256 values), then
// replaces each 'inputs' value with the closest of the quantized step values.
// 
// This operation has a gradient and thus allows for training `min` and `max` values.
func FakeQuantWithMinMaxVarsPerChannel(scope *Scope, inputs tf.Output, min tf.Output, max tf.Output)(outputs tf.Output) {
	if scope.Err() != nil {
		return
	}
	opspec := tf.OpSpec{
		Type: "FakeQuantWithMinMaxVarsPerChannel",
		Input: []tf.Input{
			inputs, min, max, 
		},
	}
	op := scope.AddOperation(opspec)
	return op.Output(0)
}

// QuantizedInstanceNormAttr is an optional argument to QuantizedInstanceNorm.
type QuantizedInstanceNormAttr func(optionalAttr)


// QuantizedInstanceNormOutputRangeGiven sets the optional output_range_given attribute to value.
//
// value: If True, `given_y_min` and `given_y_min`
// and `given_y_max` are used as the output range. Otherwise,
// the implementation computes the output range.
// If not specified, defaults to false 
func QuantizedInstanceNormOutputRangeGiven(value bool) QuantizedInstanceNormAttr {
	return func(m optionalAttr) {
		m["output_range_given"] = value
	}
}

// QuantizedInstanceNormGivenYMin sets the optional given_y_min attribute to value.
//
// value: Output in `y_min` if `output_range_given` is True.
// If not specified, defaults to 0 
func QuantizedInstanceNormGivenYMin(value float32) QuantizedInstanceNormAttr {
	return func(m optionalAttr) {
		m["given_y_min"] = value
	}
}

// QuantizedInstanceNormGivenYMax sets the optional given_y_max attribute to value.
//
// value: Output in `y_max` if `output_range_given` is True.
// If not specified, defaults to 0 
func QuantizedInstanceNormGivenYMax(value float32) QuantizedInstanceNormAttr {
	return func(m optionalAttr) {
		m["given_y_max"] = value
	}
}

// QuantizedInstanceNormVarianceEpsilon sets the optional variance_epsilon attribute to value.
//
// value: A small float number to avoid dividing by 0.
// If not specified, defaults to 1e-05 
func QuantizedInstanceNormVarianceEpsilon(value float32) QuantizedInstanceNormAttr {
	return func(m optionalAttr) {
		m["variance_epsilon"] = value
	}
}

// QuantizedInstanceNormMinSeparation sets the optional min_separation attribute to value.
//
// value: Minimum value of `y_max - y_min`
// If not specified, defaults to 0.001 
func QuantizedInstanceNormMinSeparation(value float32) QuantizedInstanceNormAttr {
	return func(m optionalAttr) {
		m["min_separation"] = value
	}
}

// Quantized Instance normalization.
//
// Arguments:
//	x: A 4D input Tensor.
//	x_min: The value represented by the lowest quantized input.
//	x_max: The value represented by the highest quantized input.
//
// Returns A 4D Tensor.The value represented by the lowest quantized output.The value represented by the highest quantized output.
func QuantizedInstanceNorm(scope *Scope, x tf.Output, x_min tf.Output, x_max tf.Output, optional ...QuantizedInstanceNormAttr)(y tf.Output, y_min tf.Output, y_max tf.Output) {
	if scope.Err() != nil {
		return
	}
	attrs := map[string]interface{}{}
	for _, a := range optional {
		a(attrs)
	}
	opspec := tf.OpSpec{
		Type: "QuantizedInstanceNorm",
		Input: []tf.Input{
			x, x_min, x_max, 
		},
		Attrs: attrs,
	}
	op := scope.AddOperation(opspec)
	return op.Output(0), op.Output(1), op.Output(2)
}

// Reshapes a quantized tensor as per the Reshape op.
//
// ```
//
// Arguments:
//	
//	shape: Defines the shape of the output tensor.
//	input_min: The minimum value of the input.
//	input_max: The maximum value of the input.
//
// Returns This value is copied from input_min.This value is copied from input_max.
func QuantizedReshape(scope *Scope, tensor tf.Output, shape tf.Output, input_min tf.Output, input_max tf.Output)(output tf.Output, output_min tf.Output, output_max tf.Output) {
	if scope.Err() != nil {
		return
	}
	opspec := tf.OpSpec{
		Type: "QuantizedReshape",
		Input: []tf.Input{
			tensor, shape, input_min, input_max, 
		},
	}
	op := scope.AddOperation(opspec)
	return op.Output(0), op.Output(1), op.Output(2)
}

// Concatenates quantized tensors along one dimension.
//
// Arguments:
//	concat_dim: 0-D.  The dimension along which to concatenate.  Must be in the
// range [0, rank(values)).
//	values: The `N` Tensors to concatenate. Their ranks and types must match,
// and their sizes must match in all dimensions except `concat_dim`.
//	input_mins: The minimum scalar values for each of the input tensors.
//	input_maxes: The maximum scalar values for each of the input tensors.
//
// Returns A `Tensor` with the concatenation of values stacked along the
// `concat_dim` dimension.  This tensor's shape matches that of `values` except
// in `concat_dim` where it has the sum of the sizes.The float value that the minimum quantized output value represents.The float value that the maximum quantized output value represents.
func QuantizedConcat(scope *Scope, concat_dim tf.Output, values []tf.Output, input_mins []tf.Output, input_maxes []tf.Output)(output tf.Output, output_min tf.Output, output_max tf.Output) {
	if scope.Err() != nil {
		return
	}
	opspec := tf.OpSpec{
		Type: "QuantizedConcat",
		Input: []tf.Input{
			concat_dim, tf.OutputList(values), tf.OutputList(input_mins), tf.OutputList(input_maxes), 
		},
	}
	op := scope.AddOperation(opspec)
	return op.Output(0), op.Output(1), op.Output(2)
}

// QuantizeAndDequantizeAttr is an optional argument to QuantizeAndDequantize.
type QuantizeAndDequantizeAttr func(optionalAttr)


// QuantizeAndDequantizeSignedInput sets the optional signed_input attribute to value.
// If not specified, defaults to true 
func QuantizeAndDequantizeSignedInput(value bool) QuantizeAndDequantizeAttr {
	return func(m optionalAttr) {
		m["signed_input"] = value
	}
}

// QuantizeAndDequantizeNumBits sets the optional num_bits attribute to value.
// If not specified, defaults to 8 
func QuantizeAndDequantizeNumBits(value int64) QuantizeAndDequantizeAttr {
	return func(m optionalAttr) {
		m["num_bits"] = value
	}
}

// QuantizeAndDequantizeRangeGiven sets the optional range_given attribute to value.
// If not specified, defaults to false 
func QuantizeAndDequantizeRangeGiven(value bool) QuantizeAndDequantizeAttr {
	return func(m optionalAttr) {
		m["range_given"] = value
	}
}

// QuantizeAndDequantizeInputMin sets the optional input_min attribute to value.
// If not specified, defaults to 0 
func QuantizeAndDequantizeInputMin(value float32) QuantizeAndDequantizeAttr {
	return func(m optionalAttr) {
		m["input_min"] = value
	}
}

// QuantizeAndDequantizeInputMax sets the optional input_max attribute to value.
// If not specified, defaults to 0 
func QuantizeAndDequantizeInputMax(value float32) QuantizeAndDequantizeAttr {
	return func(m optionalAttr) {
		m["input_max"] = value
	}
}

// Use QuantizeAndDequantizeV2 instead.
//
// DEPRECATED at GraphDef version 22: Replaced by QuantizeAndDequantizeV2
func QuantizeAndDequantize(scope *Scope, input tf.Output, optional ...QuantizeAndDequantizeAttr)(output tf.Output) {
	if scope.Err() != nil {
		return
	}
	attrs := map[string]interface{}{}
	for _, a := range optional {
		a(attrs)
	}
	opspec := tf.OpSpec{
		Type: "QuantizeAndDequantize",
		Input: []tf.Input{
			input, 
		},
		Attrs: attrs,
	}
	op := scope.AddOperation(opspec)
	return op.Output(0)
}

// QuantizedReluAttr is an optional argument to QuantizedRelu.
type QuantizedReluAttr func(optionalAttr)


// QuantizedReluOutType sets the optional out_type attribute to value.
// If not specified, defaults to DT_QUINT8 
func QuantizedReluOutType(value tf.DataType) QuantizedReluAttr {
	return func(m optionalAttr) {
		m["out_type"] = value
	}
}

// Computes Quantized Rectified Linear: `max(features, 0)`
//
// Arguments:
//	
//	min_features: The float value that the lowest quantized value represents.
//	max_features: The float value that the highest quantized value represents.
//
// Returns Has the same output shape as "features".The float value that the lowest quantized value represents.The float value that the highest quantized value represents.
func QuantizedRelu(scope *Scope, features tf.Output, min_features tf.Output, max_features tf.Output, optional ...QuantizedReluAttr)(activations tf.Output, min_activations tf.Output, max_activations tf.Output) {
	if scope.Err() != nil {
		return
	}
	attrs := map[string]interface{}{}
	for _, a := range optional {
		a(attrs)
	}
	opspec := tf.OpSpec{
		Type: "QuantizedRelu",
		Input: []tf.Input{
			features, min_features, max_features, 
		},
		Attrs: attrs,
	}
	op := scope.AddOperation(opspec)
	return op.Output(0), op.Output(1), op.Output(2)
}

// Adds Tensor 'bias' to Tensor 'input' for Quantized types.
//
// Broadcasts the values of bias on dimensions 0..N-2 of 'input'.
//
// Arguments:
//	
//	bias: A 1D bias Tensor with size matching the last dimension of 'input'.
//	min_input: The float value that the lowest quantized input value represents.
//	max_input: The float value that the highest quantized input value represents.
//	min_bias: The float value that the lowest quantized bias value represents.
//	max_bias: The float value that the highest quantized bias value represents.
//	
//
// Returns The float value that the lowest quantized output value represents.The float value that the highest quantized output value represents.
func QuantizedBiasAdd(scope *Scope, input tf.Output, bias tf.Output, min_input tf.Output, max_input tf.Output, min_bias tf.Output, max_bias tf.Output, out_type tf.DataType)(output tf.Output, min_out tf.Output, max_out tf.Output) {
	if scope.Err() != nil {
		return
	}
	attrs := map[string]interface{}{"out_type": out_type,}
	opspec := tf.OpSpec{
		Type: "QuantizedBiasAdd",
		Input: []tf.Input{
			input, bias, min_input, max_input, min_bias, max_bias, 
		},
		Attrs: attrs,
	}
	op := scope.AddOperation(opspec)
	return op.Output(0), op.Output(1), op.Output(2)
}

// Compute gradients for a FakeQuantWithMinMaxVars operation.
//
// Arguments:
//	gradients: Backpropagated gradients above the FakeQuantWithMinMaxVars operation.
//	inputs: Values passed as inputs to the FakeQuantWithMinMaxVars operation.
// min, max: Quantization interval, scalar floats.
//	
//	
//
// Returns Backpropagated gradients w.r.t. inputs:
// `gradients * (inputs >= min && inputs <= max)`.Backpropagated gradients w.r.t. min parameter:
// `sum(gradients * (inputs < min))`.Backpropagated gradients w.r.t. max parameter:
// `sum(gradients * (inputs > max))`.
func FakeQuantWithMinMaxVarsGradient(scope *Scope, gradients tf.Output, inputs tf.Output, min tf.Output, max tf.Output)(backprops_wrt_input tf.Output, backprop_wrt_min tf.Output, backprop_wrt_max tf.Output) {
	if scope.Err() != nil {
		return
	}
	opspec := tf.OpSpec{
		Type: "FakeQuantWithMinMaxVarsGradient",
		Input: []tf.Input{
			gradients, inputs, min, max, 
		},
	}
	op := scope.AddOperation(opspec)
	return op.Output(0), op.Output(1), op.Output(2)
}

// Produces the max pool of the input tensor for quantized types.
//
// Arguments:
//	input: The 4D (batch x rows x cols x depth) Tensor to MaxReduce over.
//	min_input: The float value that the lowest quantized input value represents.
//	max_input: The float value that the highest quantized input value represents.
//	ksize: The size of the window for each dimension of the input tensor.
// The length must be 4 to match the number of dimensions of the input.
//	strides: The stride of the sliding window for each dimension of the input
// tensor. The length must be 4 to match the number of dimensions of the input.
//	padding: The type of padding algorithm to use.
//
// Returns The float value that the lowest quantized output value represents.The float value that the highest quantized output value represents.
func QuantizedMaxPool(scope *Scope, input tf.Output, min_input tf.Output, max_input tf.Output, ksize []int64, strides []int64, padding string)(output tf.Output, min_output tf.Output, max_output tf.Output) {
	if scope.Err() != nil {
		return
	}
	attrs := map[string]interface{}{"ksize": ksize,"strides": strides,"padding": padding,}
	opspec := tf.OpSpec{
		Type: "QuantizedMaxPool",
		Input: []tf.Input{
			input, min_input, max_input, 
		},
		Attrs: attrs,
	}
	op := scope.AddOperation(opspec)
	return op.Output(0), op.Output(1), op.Output(2)
}

// QuantizeAndDequantizeV2Attr is an optional argument to QuantizeAndDequantizeV2.
type QuantizeAndDequantizeV2Attr func(optionalAttr)


// QuantizeAndDequantizeV2SignedInput sets the optional signed_input attribute to value.
//
// value: If the quantization is signed or unsigned.
// If not specified, defaults to true 
func QuantizeAndDequantizeV2SignedInput(value bool) QuantizeAndDequantizeV2Attr {
	return func(m optionalAttr) {
		m["signed_input"] = value
	}
}

// QuantizeAndDequantizeV2NumBits sets the optional num_bits attribute to value.
//
// value: The bitwidth of the quantization.
// If not specified, defaults to 8 
func QuantizeAndDequantizeV2NumBits(value int64) QuantizeAndDequantizeV2Attr {
	return func(m optionalAttr) {
		m["num_bits"] = value
	}
}

// QuantizeAndDequantizeV2RangeGiven sets the optional range_given attribute to value.
//
// value: If the range is given or should be computed from the tensor.
// If not specified, defaults to false 
func QuantizeAndDequantizeV2RangeGiven(value bool) QuantizeAndDequantizeV2Attr {
	return func(m optionalAttr) {
		m["range_given"] = value
	}
}

// Quantizes then dequantizes a tensor.
//
// This op simulates the precision loss from the quantized forward pass by:
// 1. Quantizing the tensor to fixed point numbers, which should match the target
//    quantization method when it is used in inference.
// 2. Dequantizing it back to floating point numbers for the following ops, most
//    likely matmul.
// 
// There are different ways to quantize. This version does not use the full range
// of the output type, choosing to elide the lowest possible value for symmetry
// (e.g., output range is -127 to 127, not -128 to 127 for signed 8 bit
// quantization), so that 0.0 maps to 0.
// 
// To perform this op, we first find the range of values in our tensor. The range
// we use is always centered on 0, so we find m such that
// 
// 1. m = max(abs(input_min), abs(input_max)) if range_given is true,
// 2. m = max(abs(min_elem(input)), abs(max_elem(input))) otherwise.
// 
// Our input tensor range is then [-m, m].
// 
// Next, we choose our fixed-point quantization buckets, [min_fixed, max_fixed].
// If signed_input is true, this is
// 
//   [min_fixed, max_fixed ] =
//       [-(1 << (num_bits - 1) - 1), (1 << (num_bits - 1)) - 1].
// 
// Otherwise, if signed_input is false, the fixed-point range is
// 
//   [min_fixed, max_fixed] = [0, (1 << num_bits) - 1].
// 
// From this we compute our scaling factor, s:
// 
//   s = (max_fixed - min_fixed) / (2 * m).
// 
// Now we can quantize and dequantize the elements of our tensor.  An element e
// is transformed into e':
// 
//   e' = (e * s).round_to_nearest() / s.
// 
// Note that we have a different number of buckets in the signed vs. unsigned
// cases.  For example, if num_bits == 8, we get 254 buckets in the signed case
// vs. 255 in the unsigned case.
// 
// For example, suppose num_bits = 8 and m = 1.  Then
// 
//   [min_fixed, max_fixed] = [-127, 127], and
//   s = (127 + 127) / 2 = 127.
// 
// Given the vector {-1, -0.5, 0, 0.3}, this is quantized to
// {-127, -63, 0, 38}, and dequantized to {-1, -63.0/127, 0, 38.0/127}.
//
// Arguments:
//	input: Tensor to quantize and then dequantize.
//	input_min: If range_given, this is the min of the range, otherwise this input
// will be ignored.
//	input_max: If range_given, this is the max of the range, otherwise this input
// will be ignored.
func QuantizeAndDequantizeV2(scope *Scope, input tf.Output, input_min tf.Output, input_max tf.Output, optional ...QuantizeAndDequantizeV2Attr)(output tf.Output) {
	if scope.Err() != nil {
		return
	}
	attrs := map[string]interface{}{}
	for _, a := range optional {
		a(attrs)
	}
	opspec := tf.OpSpec{
		Type: "QuantizeAndDequantizeV2",
		Input: []tf.Input{
			input, input_min, input_max, 
		},
		Attrs: attrs,
	}
	op := scope.AddOperation(opspec)
	return op.Output(0)
}

// QuantizedReluXAttr is an optional argument to QuantizedReluX.
type QuantizedReluXAttr func(optionalAttr)


// QuantizedReluXOutType sets the optional out_type attribute to value.
// If not specified, defaults to DT_QUINT8 
func QuantizedReluXOutType(value tf.DataType) QuantizedReluXAttr {
	return func(m optionalAttr) {
		m["out_type"] = value
	}
}

// Computes Quantized Rectified Linear X: `min(max(features, 0), max_value)`
//
// Arguments:
//	
//	
//	min_features: The float value that the lowest quantized value represents.
//	max_features: The float value that the highest quantized value represents.
//
// Returns Has the same output shape as "features".The float value that the lowest quantized value represents.The float value that the highest quantized value represents.
func QuantizedReluX(scope *Scope, features tf.Output, max_value tf.Output, min_features tf.Output, max_features tf.Output, optional ...QuantizedReluXAttr)(activations tf.Output, min_activations tf.Output, max_activations tf.Output) {
	if scope.Err() != nil {
		return
	}
	attrs := map[string]interface{}{}
	for _, a := range optional {
		a(attrs)
	}
	opspec := tf.OpSpec{
		Type: "QuantizedReluX",
		Input: []tf.Input{
			features, max_value, min_features, max_features, 
		},
		Attrs: attrs,
	}
	op := scope.AddOperation(opspec)
	return op.Output(0), op.Output(1), op.Output(2)
}

// Produces the average pool of the input tensor for quantized types.
//
// Arguments:
//	input: 4-D with shape `[batch, height, width, channels]`.
//	min_input: The float value that the lowest quantized input value represents.
//	max_input: The float value that the highest quantized input value represents.
//	ksize: The size of the window for each dimension of the input tensor.
// The length must be 4 to match the number of dimensions of the input.
//	strides: The stride of the sliding window for each dimension of the input
// tensor.  The length must be 4 to match the number of dimensions of the input.
//	padding: The type of padding algorithm to use.
//
// Returns The float value that the lowest quantized output value represents.The float value that the highest quantized output value represents.
func QuantizedAvgPool(scope *Scope, input tf.Output, min_input tf.Output, max_input tf.Output, ksize []int64, strides []int64, padding string)(output tf.Output, min_output tf.Output, max_output tf.Output) {
	if scope.Err() != nil {
		return
	}
	attrs := map[string]interface{}{"ksize": ksize,"strides": strides,"padding": padding,}
	opspec := tf.OpSpec{
		Type: "QuantizedAvgPool",
		Input: []tf.Input{
			input, min_input, max_input, 
		},
		Attrs: attrs,
	}
	op := scope.AddOperation(opspec)
	return op.Output(0), op.Output(1), op.Output(2)
}

// QuantizeV2Attr is an optional argument to QuantizeV2.
type QuantizeV2Attr func(optionalAttr)


// QuantizeV2Mode sets the optional mode attribute to value.
// If not specified, defaults to "MIN_COMBINED" 
func QuantizeV2Mode(value string) QuantizeV2Attr {
	return func(m optionalAttr) {
		m["mode"] = value
	}
}

// Quantize the 'input' tensor of type float to 'output' tensor of type 'T'.
//
// [min_range, max_range] are scalar floats that specify the range for
// the 'input' data. The 'mode' attribute controls exactly which calculations are
// used to convert the float values to their quantized equivalents.
// 
// In 'MIN_COMBINED' mode, each value of the tensor will undergo the following:
// 
// ```
// out[i] = (in[i] - min_range) * range(T) / (max_range - min_range)
// if T == qint8, out[i] -= (range(T) + 1) / 2.0
// ```
// here `range(T) = numeric_limits<T>::max() - numeric_limits<T>::min()`
// 
// *MIN_COMBINED Mode Example*
// 
// Assume the input is type float and has a possible range of [0.0, 6.0] and the
// output type is quint8 ([0, 255]). The min_range and max_range values should be
// specified as 0.0 and 6.0. Quantizing from float to quint8 will multiply each
// value of the input by 255/6 and cast to quint8.
// 
// If the output type was qint8 ([-128, 127]), the operation will additionally
// subtract each value by 128 prior to casting, so that the range of values aligns
// with the range of qint8.
// 
// If the mode is 'MIN_FIRST', then this approach is used:
// 
// ```
// number_of_steps = 1 << (# of bits in T)
// range_adjust = number_of_steps / (number_of_steps - 1)
// range = (range_max - range_min) * range_adjust
// range_scale = number_of_steps / range
// quantized = round(input * range_scale) - round(range_min * range_scale) +
//   numeric_limits<T>::min()
// quantized = max(quantized, numeric_limits<T>::min())
// quantized = min(quantized, numeric_limits<T>::max())
// ```
// 
// The biggest difference between this and MIN_COMBINED is that the minimum range
// is rounded first, before it's subtracted from the rounded value. With
// MIN_COMBINED, a small bias is introduced where repeated iterations of quantizing
// and dequantizing will introduce a larger and larger error.
// 
// One thing to watch out for is that the operator may choose to adjust the
// requested minimum and maximum values slightly during the quantization process,
// so you should always use the output ports as the range for further calculations.
// For example, if the requested minimum and maximum values are close to equal,
// they will be separated by a small epsilon value to prevent ill-formed quantized
// buffers from being created. Otherwise, you can end up with buffers where all the
// quantized values map to the same float value, which causes problems for
// operations that have to perform further calculations on them.
//
// Arguments:
//	
//	min_range: The minimum scalar value possibly produced for the input.
//	max_range: The maximum scalar value possibly produced for the input.
//	
//
// Returns The quantized data produced from the float input.The actual minimum scalar value used for the output.The actual maximum scalar value used for the output.
func QuantizeV2(scope *Scope, input tf.Output, min_range tf.Output, max_range tf.Output, T tf.DataType, optional ...QuantizeV2Attr)(output tf.Output, output_min tf.Output, output_max tf.Output) {
	if scope.Err() != nil {
		return
	}
	attrs := map[string]interface{}{"T": T,}
	for _, a := range optional {
		a(attrs)
	}
	opspec := tf.OpSpec{
		Type: "QuantizeV2",
		Input: []tf.Input{
			input, min_range, max_range, 
		},
		Attrs: attrs,
	}
	op := scope.AddOperation(opspec)
	return op.Output(0), op.Output(1), op.Output(2)
}

// DequantizeAttr is an optional argument to Dequantize.
type DequantizeAttr func(optionalAttr)


// DequantizeMode sets the optional mode attribute to value.
// If not specified, defaults to "MIN_COMBINED" 
func DequantizeMode(value string) DequantizeAttr {
	return func(m optionalAttr) {
		m["mode"] = value
	}
}

// Dequantize the 'input' tensor into a float Tensor.
//
// [min_range, max_range] are scalar floats that specify the range for
// the 'input' data. The 'mode' attribute controls exactly which calculations are
// used to convert the float values to their quantized equivalents.
// 
// In 'MIN_COMBINED' mode, each value of the tensor will undergo the following:
// 
// ```
// if T == qint8, in[i] += (range(T) + 1)/ 2.0
// out[i] = min_range + (in[i]* (max_range - min_range) / range(T))
// ```
// here `range(T) = numeric_limits<T>::max() - numeric_limits<T>::min()`
// 
// *MIN_COMBINED Mode Example*
// 
// If the input comes from a QuantizedRelu6, the output type is
// quint8 (range of 0-255) but the possible range of QuantizedRelu6 is
// 0-6.  The min_range and max_range values are therefore 0.0 and 6.0.
// Dequantize on quint8 will take each value, cast to float, and multiply
// by 6 / 255.
// Note that if quantizedtype is qint8, the operation will additionally add
// each value by 128 prior to casting.
// 
// If the mode is 'MIN_FIRST', then this approach is used:
// 
// ```
// number_of_steps = 1 << (# of bits in T)
// range_adjust = number_of_steps / (number_of_steps - 1)
// range = (range_max - range_min) * range_adjust
// range_scale = range / number_of_steps
// const double offset_input = static_cast<double>(input) - lowest_quantized;
// result = range_min + ((input - numeric_limits<T>::min()) * range_scale)
// ```
//
// Arguments:
//	
//	min_range: The minimum scalar value possibly produced for the input.
//	max_range: The maximum scalar value possibly produced for the input.
func Dequantize(scope *Scope, input tf.Output, min_range tf.Output, max_range tf.Output, optional ...DequantizeAttr)(output tf.Output) {
	if scope.Err() != nil {
		return
	}
	attrs := map[string]interface{}{}
	for _, a := range optional {
		a(attrs)
	}
	opspec := tf.OpSpec{
		Type: "Dequantize",
		Input: []tf.Input{
			input, min_range, max_range, 
		},
		Attrs: attrs,
	}
	op := scope.AddOperation(opspec)
	return op.Output(0)
}

// FakeQuantWithMinMaxArgsAttr is an optional argument to FakeQuantWithMinMaxArgs.
type FakeQuantWithMinMaxArgsAttr func(optionalAttr)


// FakeQuantWithMinMaxArgsMin sets the optional min attribute to value.
// If not specified, defaults to -6 
func FakeQuantWithMinMaxArgsMin(value float32) FakeQuantWithMinMaxArgsAttr {
	return func(m optionalAttr) {
		m["min"] = value
	}
}

// FakeQuantWithMinMaxArgsMax sets the optional max attribute to value.
// If not specified, defaults to 6 
func FakeQuantWithMinMaxArgsMax(value float32) FakeQuantWithMinMaxArgsAttr {
	return func(m optionalAttr) {
		m["max"] = value
	}
}

// Fake-quantize the 'inputs' tensor, type float to 'outputs' tensor of same type.
//
// Attributes [min; max] define the clamping range for the 'inputs' data.  Op
// divides this range into 255 steps (total of 256 values), then replaces each
// 'inputs' value with the closest of the quantized step values.
// 
// Quantization is called fake since the output is still in floating point.
func FakeQuantWithMinMaxArgs(scope *Scope, inputs tf.Output, optional ...FakeQuantWithMinMaxArgsAttr)(outputs tf.Output) {
	if scope.Err() != nil {
		return
	}
	attrs := map[string]interface{}{}
	for _, a := range optional {
		a(attrs)
	}
	opspec := tf.OpSpec{
		Type: "FakeQuantWithMinMaxArgs",
		Input: []tf.Input{
			inputs, 
		},
		Attrs: attrs,
	}
	op := scope.AddOperation(opspec)
	return op.Output(0)
}

// FakeQuantWithMinMaxArgsGradientAttr is an optional argument to FakeQuantWithMinMaxArgsGradient.
type FakeQuantWithMinMaxArgsGradientAttr func(optionalAttr)


// FakeQuantWithMinMaxArgsGradientMin sets the optional min attribute to value.
// If not specified, defaults to -6 
func FakeQuantWithMinMaxArgsGradientMin(value float32) FakeQuantWithMinMaxArgsGradientAttr {
	return func(m optionalAttr) {
		m["min"] = value
	}
}

// FakeQuantWithMinMaxArgsGradientMax sets the optional max attribute to value.
// If not specified, defaults to 6 
func FakeQuantWithMinMaxArgsGradientMax(value float32) FakeQuantWithMinMaxArgsGradientAttr {
	return func(m optionalAttr) {
		m["max"] = value
	}
}

// Compute gradients for a FakeQuantWithMinMaxArgs operation.
//
// Arguments:
//	gradients: Backpropagated gradients above the FakeQuantWithMinMaxArgs operation.
//	inputs: Values passed as inputs to the FakeQuantWithMinMaxArgs operation.
//
// Returns Backpropagated gradients below the FakeQuantWithMinMaxArgs operation:
// `gradients * (inputs >= min && inputs <= max)`.
func FakeQuantWithMinMaxArgsGradient(scope *Scope, gradients tf.Output, inputs tf.Output, optional ...FakeQuantWithMinMaxArgsGradientAttr)(backprops tf.Output) {
	if scope.Err() != nil {
		return
	}
	attrs := map[string]interface{}{}
	for _, a := range optional {
		a(attrs)
	}
	opspec := tf.OpSpec{
		Type: "FakeQuantWithMinMaxArgsGradient",
		Input: []tf.Input{
			gradients, inputs, 
		},
		Attrs: attrs,
	}
	op := scope.AddOperation(opspec)
	return op.Output(0)
}

// QuantizedMulAttr is an optional argument to QuantizedMul.
type QuantizedMulAttr func(optionalAttr)


// QuantizedMulToutput sets the optional Toutput attribute to value.
// If not specified, defaults to DT_QINT32 
func QuantizedMulToutput(value tf.DataType) QuantizedMulAttr {
	return func(m optionalAttr) {
		m["Toutput"] = value
	}
}

// Returns x * y element-wise, working on quantized buffers.
//
// Arguments:
//	
//	
//	min_x: The float value that the lowest quantized `x` value represents.
//	max_x: The float value that the highest quantized `x` value represents.
//	min_y: The float value that the lowest quantized `y` value represents.
//	max_y: The float value that the highest quantized `y` value represents.
//
// Returns The float value that the lowest quantized output value represents.The float value that the highest quantized output value represents.
// 
// *NOTE*: `QuantizedMul` supports limited forms of broadcasting. More about
// broadcasting [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
func QuantizedMul(scope *Scope, x tf.Output, y tf.Output, min_x tf.Output, max_x tf.Output, min_y tf.Output, max_y tf.Output, optional ...QuantizedMulAttr)(z tf.Output, min_z tf.Output, max_z tf.Output) {
	if scope.Err() != nil {
		return
	}
	attrs := map[string]interface{}{}
	for _, a := range optional {
		a(attrs)
	}
	opspec := tf.OpSpec{
		Type: "QuantizedMul",
		Input: []tf.Input{
			x, y, min_x, max_x, min_y, max_y, 
		},
		Attrs: attrs,
	}
	op := scope.AddOperation(opspec)
	return op.Output(0), op.Output(1), op.Output(2)
}

// Fake-quantize the 'inputs' tensor of type float via global float scalars `min`
//
// and `max` to 'outputs' tensor of same shape as `inputs`.
// 
// [min; max] is the clamping range for the 'inputs' data.  Op divides this range
// into 255 steps (total of 256 values), then replaces each 'inputs' value with the
// closest of the quantized step values.
// 
// This operation has a gradient and thus allows for training `min` and `max` values.
func FakeQuantWithMinMaxVars(scope *Scope, inputs tf.Output, min tf.Output, max tf.Output)(outputs tf.Output) {
	if scope.Err() != nil {
		return
	}
	opspec := tf.OpSpec{
		Type: "FakeQuantWithMinMaxVars",
		Input: []tf.Input{
			inputs, min, max, 
		},
	}
	op := scope.AddOperation(opspec)
	return op.Output(0)
}

// Quantized Batch normalization.
//
// This op is deprecated and will be removed in the future. Prefer
// `tf.nn.batch_normalization`.
//
// Arguments:
//	t: A 4D input Tensor.
//	t_min: The value represented by the lowest quantized input.
//	t_max: The value represented by the highest quantized input.
//	m: A 1D mean Tensor with size matching the last dimension of t.
// This is the first output from tf.nn.moments,
// or a saved moving average thereof.
//	m_min: The value represented by the lowest quantized mean.
//	m_max: The value represented by the highest quantized mean.
//	v: A 1D variance Tensor with size matching the last dimension of t.
// This is the second output from tf.nn.moments,
// or a saved moving average thereof.
//	v_min: The value represented by the lowest quantized variance.
//	v_max: The value represented by the highest quantized variance.
//	beta: A 1D beta Tensor with size matching the last dimension of t.
// An offset to be added to the normalized tensor.
//	beta_min: The value represented by the lowest quantized offset.
//	beta_max: The value represented by the highest quantized offset.
//	gamma: A 1D gamma Tensor with size matching the last dimension of t.
// If "scale_after_normalization" is true, this tensor will be multiplied
// with the normalized tensor.
//	gamma_min: The value represented by the lowest quantized gamma.
//	gamma_max: The value represented by the highest quantized gamma.
//	
//	variance_epsilon: A small float number to avoid dividing by 0.
//	scale_after_normalization: A bool indicating whether the resulted tensor
// needs to be multiplied with gamma.
func QuantizedBatchNormWithGlobalNormalization(scope *Scope, t tf.Output, t_min tf.Output, t_max tf.Output, m tf.Output, m_min tf.Output, m_max tf.Output, v tf.Output, v_min tf.Output, v_max tf.Output, beta tf.Output, beta_min tf.Output, beta_max tf.Output, gamma tf.Output, gamma_min tf.Output, gamma_max tf.Output, out_type tf.DataType, variance_epsilon float32, scale_after_normalization bool)(result tf.Output, result_min tf.Output, result_max tf.Output) {
	if scope.Err() != nil {
		return
	}
	attrs := map[string]interface{}{"out_type": out_type,"variance_epsilon": variance_epsilon,"scale_after_normalization": scale_after_normalization,}
	opspec := tf.OpSpec{
		Type: "QuantizedBatchNormWithGlobalNormalization",
		Input: []tf.Input{
			t, t_min, t_max, m, m_min, m_max, v, v_min, v_max, beta, beta_min, beta_max, gamma, gamma_min, gamma_max, 
		},
		Attrs: attrs,
	}
	op := scope.AddOperation(opspec)
	return op.Output(0), op.Output(1), op.Output(2)
}

// QuantizedRelu6Attr is an optional argument to QuantizedRelu6.
type QuantizedRelu6Attr func(optionalAttr)


// QuantizedRelu6OutType sets the optional out_type attribute to value.
// If not specified, defaults to DT_QUINT8 
func QuantizedRelu6OutType(value tf.DataType) QuantizedRelu6Attr {
	return func(m optionalAttr) {
		m["out_type"] = value
	}
}

// Computes Quantized Rectified Linear 6: `min(max(features, 0), 6)`
//
// Arguments:
//	
//	min_features: The float value that the lowest quantized value represents.
//	max_features: The float value that the highest quantized value represents.
//
// Returns Has the same output shape as "features".The float value that the lowest quantized value represents.The float value that the highest quantized value represents.
func QuantizedRelu6(scope *Scope, features tf.Output, min_features tf.Output, max_features tf.Output, optional ...QuantizedRelu6Attr)(activations tf.Output, min_activations tf.Output, max_activations tf.Output) {
	if scope.Err() != nil {
		return
	}
	attrs := map[string]interface{}{}
	for _, a := range optional {
		a(attrs)
	}
	opspec := tf.OpSpec{
		Type: "QuantizedRelu6",
		Input: []tf.Input{
			features, min_features, max_features, 
		},
		Attrs: attrs,
	}
	op := scope.AddOperation(opspec)
	return op.Output(0), op.Output(1), op.Output(2)
}

// Given a quantized tensor described by (input, input_min, input_max), outputs a
//
// range that covers the actual values present in that tensor.  This op is
// typically used to produce the requested_output_min and requested_output_max for
// Requantize.
//
// Arguments:
//	
//	input_min: The float value that the minimum quantized input value represents.
//	input_max: The float value that the maximum quantized input value represents.
//
// Returns The computed min output.the computed max output.
func RequantizationRange(scope *Scope, input tf.Output, input_min tf.Output, input_max tf.Output)(output_min tf.Output, output_max tf.Output) {
	if scope.Err() != nil {
		return
	}
	opspec := tf.OpSpec{
		Type: "RequantizationRange",
		Input: []tf.Input{
			input, input_min, input_max, 
		},
	}
	op := scope.AddOperation(opspec)
	return op.Output(0), op.Output(1)
}

// Convert the quantized 'input' tensor into a lower-precision 'output', using the
//
// actual distribution of the values to maximize the usage of the lower bit depth
// and adjusting the output min and max ranges accordingly.
// 
// [input_min, input_max] are scalar floats that specify the range for the float
// interpretation of the 'input' data. For example, if input_min is -1.0f and
// input_max is 1.0f, and we are dealing with quint16 quantized data, then a 0
// value in the 16-bit data should be interpreted as -1.0f, and a 65535 means 1.0f.
// 
// This operator tries to squeeze as much precision as possible into an output with
// a lower bit depth by calculating the actual min and max values found in the
// data. For example, maybe that quint16 input has no values lower than 16,384 and
// none higher than 49,152. That means only half the range is actually needed, all
// the float interpretations are between -0.5f and 0.5f, so if we want to compress
// the data into a quint8 output, we can use that range rather than the theoretical
// -1.0f to 1.0f that is suggested by the input min and max.
// 
// In practice, this is most useful for taking output from operations like
// QuantizedMatMul that can produce higher bit-depth outputs than their inputs and
// may have large potential output ranges, but in practice have a distribution of
// input values that only uses a small fraction of the possible range. By feeding
// that output into this operator, we can reduce it from 32 bits down to 8 with
// minimal loss of accuracy.
//
// Arguments:
//	
//	input_min: The float value that the minimum quantized input value represents.
//	input_max: The float value that the maximum quantized input value represents.
//	out_type: The type of the output. Should be a lower bit depth than Tinput.
//
// Returns The float value that the minimum quantized output value represents.The float value that the maximum quantized output value represents.
func QuantizeDownAndShrinkRange(scope *Scope, input tf.Output, input_min tf.Output, input_max tf.Output, out_type tf.DataType)(output tf.Output, output_min tf.Output, output_max tf.Output) {
	if scope.Err() != nil {
		return
	}
	attrs := map[string]interface{}{"out_type": out_type,}
	opspec := tf.OpSpec{
		Type: "QuantizeDownAndShrinkRange",
		Input: []tf.Input{
			input, input_min, input_max, 
		},
		Attrs: attrs,
	}
	op := scope.AddOperation(opspec)
	return op.Output(0), op.Output(1), op.Output(2)
}

// QuantizedMatMulAttr is an optional argument to QuantizedMatMul.
type QuantizedMatMulAttr func(optionalAttr)


// QuantizedMatMulToutput sets the optional Toutput attribute to value.
// If not specified, defaults to DT_QINT32 
func QuantizedMatMulToutput(value tf.DataType) QuantizedMatMulAttr {
	return func(m optionalAttr) {
		m["Toutput"] = value
	}
}

// QuantizedMatMulTransposeA sets the optional transpose_a attribute to value.
//
// value: If true, `a` is transposed before multiplication.
// If not specified, defaults to false 
func QuantizedMatMulTransposeA(value bool) QuantizedMatMulAttr {
	return func(m optionalAttr) {
		m["transpose_a"] = value
	}
}

// QuantizedMatMulTransposeB sets the optional transpose_b attribute to value.
//
// value: If true, `b` is transposed before multiplication.
// If not specified, defaults to false 
func QuantizedMatMulTransposeB(value bool) QuantizedMatMulAttr {
	return func(m optionalAttr) {
		m["transpose_b"] = value
	}
}

// QuantizedMatMulTactivation sets the optional Tactivation attribute to value.
//
// value: The type of output produced by activation function
// following this operation.
// If not specified, defaults to DT_QUINT8 
func QuantizedMatMulTactivation(value tf.DataType) QuantizedMatMulAttr {
	return func(m optionalAttr) {
		m["Tactivation"] = value
	}
}

// Perform a quantized matrix multiplication of  `a` by the matrix `b`.
//
// The inputs must be two-dimensional matrices and the inner dimension of
// `a` (after being transposed if `transpose_a` is non-zero) must match the
// outer dimension of `b` (after being transposed if `transposed_b` is
// non-zero).
//
// Arguments:
//	a: Must be a two-dimensional tensor.
//	b: Must be a two-dimensional tensor.
//	min_a: The float value that the lowest quantized `a` value represents.
//	max_a: The float value that the highest quantized `a` value represents.
//	min_b: The float value that the lowest quantized `b` value represents.
//	max_b: The float value that the highest quantized `b` value represents.
//
// Returns The float value that the lowest quantized output value represents.The float value that the highest quantized output value represents.
func QuantizedMatMul(scope *Scope, a tf.Output, b tf.Output, min_a tf.Output, max_a tf.Output, min_b tf.Output, max_b tf.Output, optional ...QuantizedMatMulAttr)(out tf.Output, min_out tf.Output, max_out tf.Output) {
	if scope.Err() != nil {
		return
	}
	attrs := map[string]interface{}{}
	for _, a := range optional {
		a(attrs)
	}
	opspec := tf.OpSpec{
		Type: "QuantizedMatMul",
		Input: []tf.Input{
			a, b, min_a, max_a, min_b, max_b, 
		},
		Attrs: attrs,
	}
	op := scope.AddOperation(opspec)
	return op.Output(0), op.Output(1), op.Output(2)
}

// Convert the quantized 'input' tensor into a lower-precision 'output', using the
//
// output range specified with 'requested_output_min' and 'requested_output_max'.
// 
// [input_min, input_max] are scalar floats that specify the range for the float
// interpretation of the 'input' data. For example, if input_min is -1.0f and
// input_max is 1.0f, and we are dealing with quint16 quantized data, then a 0
// value in the 16-bit data should be interpreted as -1.0f, and a 65535 means 1.0f.
//
// Arguments:
//	
//	input_min: The float value that the minimum quantized input value represents.
//	input_max: The float value that the maximum quantized input value represents.
//	requested_output_min: The float value that the minimum quantized output value represents.
//	requested_output_max: The float value that the maximum quantized output value represents.
//	out_type: The type of the output. Should be a lower bit depth than Tinput.
//
// Returns The requested_output_min value is copied into this output.The requested_output_max value is copied into this output.
func Requantize(scope *Scope, input tf.Output, input_min tf.Output, input_max tf.Output, requested_output_min tf.Output, requested_output_max tf.Output, out_type tf.DataType)(output tf.Output, output_min tf.Output, output_max tf.Output) {
	if scope.Err() != nil {
		return
	}
	attrs := map[string]interface{}{"out_type": out_type,}
	opspec := tf.OpSpec{
		Type: "Requantize",
		Input: []tf.Input{
			input, input_min, input_max, requested_output_min, requested_output_max, 
		},
		Attrs: attrs,
	}
	op := scope.AddOperation(opspec)
	return op.Output(0), op.Output(1), op.Output(2)
}

// Compute gradients for a FakeQuantWithMinMaxVarsPerChannel operation.
//
// Arguments:
//	gradients: Backpropagated gradients above the FakeQuantWithMinMaxVars operation,
// shape one of: `[d]`, `[b, d]`,  `[b, h, w, d]`.
//	inputs: Values passed as inputs to the FakeQuantWithMinMaxVars operation, shape
//   same as `gradients`.
// min, max: Quantization interval, floats of shape `[d]`.
//	
//	
//
// Returns Backpropagated gradients w.r.t. inputs, shape same as
// `inputs`:
//   `gradients * (inputs >= min && inputs <= max)`.Backpropagated gradients w.r.t. min parameter, shape `[d]`:
// `sum_per_d(gradients * (inputs < min))`.Backpropagated gradients w.r.t. max parameter, shape `[d]`:
// `sum_per_d(gradients * (inputs > max))`.
func FakeQuantWithMinMaxVarsPerChannelGradient(scope *Scope, gradients tf.Output, inputs tf.Output, min tf.Output, max tf.Output)(backprops_wrt_input tf.Output, backprop_wrt_min tf.Output, backprop_wrt_max tf.Output) {
	if scope.Err() != nil {
		return
	}
	opspec := tf.OpSpec{
		Type: "FakeQuantWithMinMaxVarsPerChannelGradient",
		Input: []tf.Input{
			gradients, inputs, min, max, 
		},
	}
	op := scope.AddOperation(opspec)
	return op.Output(0), op.Output(1), op.Output(2)
}

// Fake-quantize the 'inputs' tensor of type float and one of the shapes: `[d]`,
//
// `[b, d]` `[b, h, w, d]` via per-channel floats `min` and `max` of shape `[d]`
// to 'outputs' tensor of same shape as `inputs`.
// 
// [min; max] is the clamping range for the 'inputs' data in the corresponding
// depth channel.  Op divides this range into 255 steps (total of 256 values), then
// replaces each 'inputs' value with the closest of the quantized step values.
// 
// This operation has a gradient and thus allows for training `min` and `max` values.
func FakeQuantWithMinMaxVarsPerChannel(scope *Scope, inputs tf.Output, min tf.Output, max tf.Output)(outputs tf.Output) {
	if scope.Err() != nil {
		return
	}
	opspec := tf.OpSpec{
		Type: "FakeQuantWithMinMaxVarsPerChannel",
		Input: []tf.Input{
			inputs, min, max, 
		},
	}
	op := scope.AddOperation(opspec)
	return op.Output(0)
}

// QuantizedInstanceNormAttr is an optional argument to QuantizedInstanceNorm.
type QuantizedInstanceNormAttr func(optionalAttr)


// QuantizedInstanceNormOutputRangeGiven sets the optional output_range_given attribute to value.
//
// value: If True, `given_y_min` and `given_y_min`
// and `given_y_max` are used as the output range. Otherwise,
// the implementation computes the output range.
// If not specified, defaults to false 
func QuantizedInstanceNormOutputRangeGiven(value bool) QuantizedInstanceNormAttr {
	return func(m optionalAttr) {
		m["output_range_given"] = value
	}
}

// QuantizedInstanceNormGivenYMin sets the optional given_y_min attribute to value.
//
// value: Output in `y_min` if `output_range_given` is True.
// If not specified, defaults to 0 
func QuantizedInstanceNormGivenYMin(value float32) QuantizedInstanceNormAttr {
	return func(m optionalAttr) {
		m["given_y_min"] = value
	}
}

// QuantizedInstanceNormGivenYMax sets the optional given_y_max attribute to value.
//
// value: Output in `y_max` if `output_range_given` is True.
// If not specified, defaults to 0 
func QuantizedInstanceNormGivenYMax(value float32) QuantizedInstanceNormAttr {
	return func(m optionalAttr) {
		m["given_y_max"] = value
	}
}

// QuantizedInstanceNormVarianceEpsilon sets the optional variance_epsilon attribute to value.
//
// value: A small float number to avoid dividing by 0.
// If not specified, defaults to 1e-05 
func QuantizedInstanceNormVarianceEpsilon(value float32) QuantizedInstanceNormAttr {
	return func(m optionalAttr) {
		m["variance_epsilon"] = value
	}
}

// QuantizedInstanceNormMinSeparation sets the optional min_separation attribute to value.
//
// value: Minimum value of `y_max - y_min`
// If not specified, defaults to 0.001 
func QuantizedInstanceNormMinSeparation(value float32) QuantizedInstanceNormAttr {
	return func(m optionalAttr) {
		m["min_separation"] = value
	}
}

// Quantized Instance normalization.
//
// Arguments:
//	x: A 4D input Tensor.
//	x_min: The value represented by the lowest quantized input.
//	x_max: The value represented by the highest quantized input.
//
// Returns A 4D Tensor.The value represented by the lowest quantized output.The value represented by the highest quantized output.
func QuantizedInstanceNorm(scope *Scope, x tf.Output, x_min tf.Output, x_max tf.Output, optional ...QuantizedInstanceNormAttr)(y tf.Output, y_min tf.Output, y_max tf.Output) {
	if scope.Err() != nil {
		return
	}
	attrs := map[string]interface{}{}
	for _, a := range optional {
		a(attrs)
	}
	opspec := tf.OpSpec{
		Type: "QuantizedInstanceNorm",
		Input: []tf.Input{
			x, x_min, x_max, 
		},
		Attrs: attrs,
	}
	op := scope.AddOperation(opspec)
	return op.Output(0), op.Output(1), op.Output(2)
}

// Reshapes a quantized tensor as per the Reshape op.
//
// ```
//
// Arguments:
//	
//	shape: Defines the shape of the output tensor.
//	input_min: The minimum value of the input.
//	input_max: The maximum value of the input.
//
// Returns This value is copied from input_min.This value is copied from input_max.
func QuantizedReshape(scope *Scope, tensor tf.Output, shape tf.Output, input_min tf.Output, input_max tf.Output)(output tf.Output, output_min tf.Output, output_max tf.Output) {
	if scope.Err() != nil {
		return
	}
	opspec := tf.OpSpec{
		Type: "QuantizedReshape",
		Input: []tf.Input{
			tensor, shape, input_min, input_max, 
		},
	}
	op := scope.AddOperation(opspec)
	return op.Output(0), op.Output(1), op.Output(2)
}

// Concatenates quantized tensors along one dimension.
//
// Arguments:
//	concat_dim: 0-D.  The dimension along which to concatenate.  Must be in the
// range [0, rank(values)).
//	values: The `N` Tensors to concatenate. Their ranks and types must match,
// and their sizes must match in all dimensions except `concat_dim`.
//	input_mins: The minimum scalar values for each of the input tensors.
//	input_maxes: The maximum scalar values for each of the input tensors.
//
// Returns A `Tensor` with the concatenation of values stacked along the
// `concat_dim` dimension.  This tensor's shape matches that of `values` except
// in `concat_dim` where it has the sum of the sizes.The float value that the minimum quantized output value represents.The float value that the maximum quantized output value represents.
func QuantizedConcat(scope *Scope, concat_dim tf.Output, values []tf.Output, input_mins []tf.Output, input_maxes []tf.Output)(output tf.Output, output_min tf.Output, output_max tf.Output) {
	if scope.Err() != nil {
		return
	}
	opspec := tf.OpSpec{
		Type: "QuantizedConcat",
		Input: []tf.Input{
			concat_dim, tf.OutputList(values), tf.OutputList(input_mins), tf.OutputList(input_maxes), 
		},
	}
	op := scope.AddOperation(opspec)
	return op.Output(0), op.Output(1), op.Output(2)
}

// QuantizeAndDequantizeAttr is an optional argument to QuantizeAndDequantize.
type QuantizeAndDequantizeAttr func(optionalAttr)


// QuantizeAndDequantizeSignedInput sets the optional signed_input attribute to value.
// If not specified, defaults to true 
func QuantizeAndDequantizeSignedInput(value bool) QuantizeAndDequantizeAttr {
	return func(m optionalAttr) {
		m["signed_input"] = value
	}
}

// QuantizeAndDequantizeNumBits sets the optional num_bits attribute to value.
// If not specified, defaults to 8 
func QuantizeAndDequantizeNumBits(value int64) QuantizeAndDequantizeAttr {
	return func(m optionalAttr) {
		m["num_bits"] = value
	}
}

// QuantizeAndDequantizeRangeGiven sets the optional range_given attribute to value.
// If not specified, defaults to false 
func QuantizeAndDequantizeRangeGiven(value bool) QuantizeAndDequantizeAttr {
	return func(m optionalAttr) {
		m["range_given"] = value
	}
}

// QuantizeAndDequantizeInputMin sets the optional input_min attribute to value.
// If not specified, defaults to 0 
func QuantizeAndDequantizeInputMin(value float32) QuantizeAndDequantizeAttr {
	return func(m optionalAttr) {
		m["input_min"] = value
	}
}

// QuantizeAndDequantizeInputMax sets the optional input_max attribute to value.
// If not specified, defaults to 0 
func QuantizeAndDequantizeInputMax(value float32) QuantizeAndDequantizeAttr {
	return func(m optionalAttr) {
		m["input_max"] = value
	}
}

// Use QuantizeAndDequantizeV2 instead.
//
// DEPRECATED at GraphDef version 22: Replaced by QuantizeAndDequantizeV2
func QuantizeAndDequantize(scope *Scope, input tf.Output, optional ...QuantizeAndDequantizeAttr)(output tf.Output) {
	if scope.Err() != nil {
		return
	}
	attrs := map[string]interface{}{}
	for _, a := range optional {
		a(attrs)
	}
	opspec := tf.OpSpec{
		Type: "QuantizeAndDequantize",
		Input: []tf.Input{
			input, 
		},
		Attrs: attrs,
	}
	op := scope.AddOperation(opspec)
	return op.Output(0)
}

// QuantizedReluAttr is an optional argument to QuantizedRelu.
type QuantizedReluAttr func(optionalAttr)


// QuantizedReluOutType sets the optional out_type attribute to value.
// If not specified, defaults to DT_QUINT8 
func QuantizedReluOutType(value tf.DataType) QuantizedReluAttr {
	return func(m optionalAttr) {
		m["out_type"] = value
	}
}

// Computes Quantized Rectified Linear: `max(features, 0)`
//
// Arguments:
//	
//	min_features: The float value that the lowest quantized value represents.
//	max_features: The float value that the highest quantized value represents.
//
// Returns Has the same output shape as "features".The float value that the lowest quantized value represents.The float value that the highest quantized value represents.
func QuantizedRelu(scope *Scope, features tf.Output, min_features tf.Output, max_features tf.Output, optional ...QuantizedReluAttr)(activations tf.Output, min_activations tf.Output, max_activations tf.Output) {
	if scope.Err() != nil {
		return
	}
	attrs := map[string]interface{}{}
	for _, a := range optional {
		a(attrs)
	}
	opspec := tf.OpSpec{
		Type: "QuantizedRelu",
		Input: []tf.Input{
			features, min_features, max_features, 
		},
		Attrs: attrs,
	}
	op := scope.AddOperation(opspec)
	return op.Output(0), op.Output(1), op.Output(2)
}

// Adds Tensor 'bias' to Tensor 'input' for Quantized types.
//
// Broadcasts the values of bias on dimensions 0..N-2 of 'input'.
//
// Arguments:
//	
//	bias: A 1D bias Tensor with size matching the last dimension of 'input'.
//	min_input: The float value that the lowest quantized input value represents.
//	max_input: The float value that the highest quantized input value represents.
//	min_bias: The float value that the lowest quantized bias value represents.
//	max_bias: The float value that the highest quantized bias value represents.
//	
//
// Returns The float value that the lowest quantized output value represents.The float value that the highest quantized output value represents.
func QuantizedBiasAdd(scope *Scope, input tf.Output, bias tf.Output, min_input tf.Output, max_input tf.Output, min_bias tf.Output, max_bias tf.Output, out_type tf.DataType)(output tf.Output, min_out tf.Output, max_out tf.Output) {
	if scope.Err() != nil {
		return
	}
	attrs := map[string]interface{}{"out_type": out_type,}
	opspec := tf.OpSpec{
		Type: "QuantizedBiasAdd",
		Input: []tf.Input{
			input, bias, min_input, max_input, min_bias, max_bias, 
		},
		Attrs: attrs,
	}
	op := scope.AddOperation(opspec)
	return op.Output(0), op.Output(1), op.Output(2)
}

// Compute gradients for a FakeQuantWithMinMaxVars operation.
//
// Arguments:
//	gradients: Backpropagated gradients above the FakeQuantWithMinMaxVars operation.
//	inputs: Values passed as inputs to the FakeQuantWithMinMaxVars operation.
// min, max: Quantization interval, scalar floats.
//	
//	
//
// Returns Backpropagated gradients w.r.t. inputs:
// `gradients * (inputs >= min && inputs <= max)`.Backpropagated gradients w.r.t. min parameter:
// `sum(gradients * (inputs < min))`.Backpropagated gradients w.r.t. max parameter:
// `sum(gradients * (inputs > max))`.
func FakeQuantWithMinMaxVarsGradient(scope *Scope, gradients tf.Output, inputs tf.Output, min tf.Output, max tf.Output)(backprops_wrt_input tf.Output, backprop_wrt_min tf.Output, backprop_wrt_max tf.Output) {
	if scope.Err() != nil {
		return
	}
	opspec := tf.OpSpec{
		Type: "FakeQuantWithMinMaxVarsGradient",
		Input: []tf.Input{
			gradients, inputs, min, max, 
		},
	}
	op := scope.AddOperation(opspec)
	return op.Output(0), op.Output(1), op.Output(2)
}

// Produces the max pool of the input tensor for quantized types.
//
// Arguments:
//	input: The 4D (batch x rows x cols x depth) Tensor to MaxReduce over.
//	min_input: The float value that the lowest quantized input value represents.
//	max_input: The float value that the highest quantized input value represents.
//	ksize: The size of the window for each dimension of the input tensor.
// The length must be 4 to match the number of dimensions of the input.
//	strides: The stride of the sliding window for each dimension of the input
// tensor. The length must be 4 to match the number of dimensions of the input.
//	padding: The type of padding algorithm to use.
//
// Returns The float value that the lowest quantized output value represents.The float value that the highest quantized output value represents.
func QuantizedMaxPool(scope *Scope, input tf.Output, min_input tf.Output, max_input tf.Output, ksize []int64, strides []int64, padding string)(output tf.Output, min_output tf.Output, max_output tf.Output) {
	if scope.Err() != nil {
		return
	}
	attrs := map[string]interface{}{"ksize": ksize,"strides": strides,"padding": padding,}
	opspec := tf.OpSpec{
		Type: "QuantizedMaxPool",
		Input: []tf.Input{
			input, min_input, max_input, 
		},
		Attrs: attrs,
	}
	op := scope.AddOperation(opspec)
	return op.Output(0), op.Output(1), op.Output(2)
}

// QuantizeAndDequantizeV2Attr is an optional argument to QuantizeAndDequantizeV2.
type QuantizeAndDequantizeV2Attr func(optionalAttr)


// QuantizeAndDequantizeV2SignedInput sets the optional signed_input attribute to value.
//
// value: If the quantization is signed or unsigned.
// If not specified, defaults to true 
func QuantizeAndDequantizeV2SignedInput(value bool) QuantizeAndDequantizeV2Attr {
	return func(m optionalAttr) {
		m["signed_input"] = value
	}
}

// QuantizeAndDequantizeV2NumBits sets the optional num_bits attribute to value.
//
// value: The bitwidth of the quantization.
// If not specified, defaults to 8 
func QuantizeAndDequantizeV2NumBits(value int64) QuantizeAndDequantizeV2Attr {
	return func(m optionalAttr) {
		m["num_bits"] = value
	}
}

// QuantizeAndDequantizeV2RangeGiven sets the optional range_given attribute to value.
//
// value: If the range is given or should be computed from the tensor.
// If not specified, defaults to false 
func QuantizeAndDequantizeV2RangeGiven(value bool) QuantizeAndDequantizeV2Attr {
	return func(m optionalAttr) {
		m["range_given"] = value
	}
}

// Quantizes then dequantizes a tensor.
//
// This op simulates the precision loss from the quantized forward pass by:
// 1. Quantizing the tensor to fixed point numbers, which should match the target
//    quantization method when it is used in inference.
// 2. Dequantizing it back to floating point numbers for the following ops, most
//    likely matmul.
// 
// There are different ways to quantize. This version does not use the full range
// of the output type, choosing to elide the lowest possible value for symmetry
// (e.g., output range is -127 to 127, not -128 to 127 for signed 8 bit
// quantization), so that 0.0 maps to 0.
// 
// To perform this op, we first find the range of values in our tensor. The range
// we use is always centered on 0, so we find m such that
// 
// 1. m = max(abs(input_min), abs(input_max)) if range_given is true,
// 2. m = max(abs(min_elem(input)), abs(max_elem(input))) otherwise.
// 
// Our input tensor range is then [-m, m].
// 
// Next, we choose our fixed-point quantization buckets, [min_fixed, max_fixed].
// If signed_input is true, this is
// 
//   [min_fixed, max_fixed ] =
//       [-(1 << (num_bits - 1) - 1), (1 << (num_bits - 1)) - 1].
// 
// Otherwise, if signed_input is false, the fixed-point range is
// 
//   [min_fixed, max_fixed] = [0, (1 << num_bits) - 1].
// 
// From this we compute our scaling factor, s:
// 
//   s = (max_fixed - min_fixed) / (2 * m).
// 
// Now we can quantize and dequantize the elements of our tensor.  An element e
// is transformed into e':
// 
//   e' = (e * s).round_to_nearest() / s.
// 
// Note that we have a different number of buckets in the signed vs. unsigned
// cases.  For example, if num_bits == 8, we get 254 buckets in the signed case
// vs. 255 in the unsigned case.
// 
// For example, suppose num_bits = 8 and m = 1.  Then
// 
//   [min_fixed, max_fixed] = [-127, 127], and
//   s = (127 + 127) / 2 = 127.
// 
// Given the vector {-1, -0.5, 0, 0.3}, this is quantized to
// {-127, -63, 0, 38}, and dequantized to {-1, -63.0/127, 0, 38.0/127}.
//
// Arguments:
//	input: Tensor to quantize and then dequantize.
//	input_min: If range_given, this is the min of the range, otherwise this input
// will be ignored.
//	input_max: If range_given, this is the max of the range, otherwise this input
// will be ignored.
func QuantizeAndDequantizeV2(scope *Scope, input tf.Output, input_min tf.Output, input_max tf.Output, optional ...QuantizeAndDequantizeV2Attr)(output tf.Output) {
	if scope.Err() != nil {
		return
	}
	attrs := map[string]interface{}{}
	for _, a := range optional {
		a(attrs)
	}
	opspec := tf.OpSpec{
		Type: "QuantizeAndDequantizeV2",
		Input: []tf.Input{
			input, input_min, input_max, 
		},
		Attrs: attrs,
	}
	op := scope.AddOperation(opspec)
	return op.Output(0)
}

// QuantizedReluXAttr is an optional argument to QuantizedReluX.
type QuantizedReluXAttr func(optionalAttr)


// QuantizedReluXOutType sets the optional out_type attribute to value.
// If not specified, defaults to DT_QUINT8 
func QuantizedReluXOutType(value tf.DataType) QuantizedReluXAttr {
	return func(m optionalAttr) {
		m["out_type"] = value
	}
}

// Computes Quantized Rectified Linear X: `min(max(features, 0), max_value)`
//
// Arguments:
//	
//	
//	min_features: The float value that the lowest quantized value represents.
//	max_features: The float value that the highest quantized value represents.
//
// Returns Has the same output shape as "features".The float value that the lowest quantized value represents.The float value that the highest quantized value represents.
func QuantizedReluX(scope *Scope, features tf.Output, max_value tf.Output, min_features tf.Output, max_features tf.Output, optional ...QuantizedReluXAttr)(activations tf.Output, min_activations tf.Output, max_activations tf.Output) {
	if scope.Err() != nil {
		return
	}
	attrs := map[string]interface{}{}
	for _, a := range optional {
		a(attrs)
	}
	opspec := tf.OpSpec{
		Type: "QuantizedReluX",
		Input: []tf.Input{
			features, max_value, min_features, max_features, 
		},
		Attrs: attrs,
	}
	op := scope.AddOperation(opspec)
	return op.Output(0), op.Output(1), op.Output(2)
}

// Produces the average pool of the input tensor for quantized types.
//
// Arguments:
//	input: 4-D with shape `[batch, height, width, channels]`.
//	min_input: The float value that the lowest quantized input value represents.
//	max_input: The float value that the highest quantized input value represents.
//	ksize: The size of the window for each dimension of the input tensor.
// The length must be 4 to match the number of dimensions of the input.
//	strides: The stride of the sliding window for each dimension of the input
// tensor.  The length must be 4 to match the number of dimensions of the input.
//	padding: The type of padding algorithm to use.
//
// Returns The float value that the lowest quantized output value represents.The float value that the highest quantized output value represents.
func QuantizedAvgPool(scope *Scope, input tf.Output, min_input tf.Output, max_input tf.Output, ksize []int64, strides []int64, padding string)(output tf.Output, min_output tf.Output, max_output tf.Output) {
	if scope.Err() != nil {
		return
	}
	attrs := map[string]interface{}{"ksize": ksize,"strides": strides,"padding": padding,}
	opspec := tf.OpSpec{
		Type: "QuantizedAvgPool",
		Input: []tf.Input{
			input, min_input, max_input, 
		},
		Attrs: attrs,
	}
	op := scope.AddOperation(opspec)
	return op.Output(0), op.Output(1), op.Output(2)
}

// QuantizeV2Attr is an optional argument to QuantizeV2.
type QuantizeV2Attr func(optionalAttr)


// QuantizeV2Mode sets the optional mode attribute to value.
// If not specified, defaults to "MIN_COMBINED" 
func QuantizeV2Mode(value string) QuantizeV2Attr {
	return func(m optionalAttr) {
		m["mode"] = value
	}
}

// Quantize the 'input' tensor of type float to 'output' tensor of type 'T'.
//
// [min_range, max_range] are scalar floats that specify the range for
// the 'input' data. The 'mode' attribute controls exactly which calculations are
// used to convert the float values to their quantized equivalents.
// 
// In 'MIN_COMBINED' mode, each value of the tensor will undergo the following:
// 
// ```
// out[i] = (in[i] - min_range) * range(T) / (max_range - min_range)
// if T == qint8, out[i] -= (range(T) + 1) / 2.0
// ```
// here `range(T) = numeric_limits<T>::max() - numeric_limits<T>::min()`
// 
// *MIN_COMBINED Mode Example*
// 
// Assume the input is type float and has a possible range of [0.0, 6.0] and the
// output type is quint8 ([0, 255]). The min_range and max_range values should be
// specified as 0.0 and 6.0. Quantizing from float to quint8 will multiply each
// value of the input by 255/6 and cast to quint8.
// 
// If the output type was qint8 ([-128, 127]), the operation will additionally
// subtract each value by 128 prior to casting, so that the range of values aligns
// with the range of qint8.
// 
// If the mode is 'MIN_FIRST', then this approach is used:
// 
// ```
// number_of_steps = 1 << (# of bits in T)
// range_adjust = number_of_steps / (number_of_steps - 1)
// range = (range_max - range_min) * range_adjust
// range_scale = number_of_steps / range
// quantized = round(input * range_scale) - round(range_min * range_scale) +
//   numeric_limits<T>::min()
// quantized = max(quantized, numeric_limits<T>::min())
// quantized = min(quantized, numeric_limits<T>::max())
// ```
// 
// The biggest difference between this and MIN_COMBINED is that the minimum range
// is rounded first, before it's subtracted from the rounded value. With
// MIN_COMBINED, a small bias is introduced where repeated iterations of quantizing
// and dequantizing will introduce a larger and larger error.
// 
// One thing to watch out for is that the operator may choose to adjust the
// requested minimum and maximum values slightly during the quantization process,
// so you should always use the output ports as the range for further calculations.
// For example, if the requested minimum and maximum values are close to equal,
// they will be separated by a small epsilon value to prevent ill-formed quantized
// buffers from being created. Otherwise, you can end up with buffers where all the
// quantized values map to the same float value, which causes problems for
// operations that have to perform further calculations on them.
//
// Arguments:
//	
//	min_range: The minimum scalar value possibly produced for the input.
//	max_range: The maximum scalar value possibly produced for the input.
//	
//
// Returns The quantized data produced from the float input.The actual minimum scalar value used for the output.The actual maximum scalar value used for the output.
func QuantizeV2(scope *Scope, input tf.Output, min_range tf.Output, max_range tf.Output, T tf.DataType, optional ...QuantizeV2Attr)(output tf.Output, output_min tf.Output, output_max tf.Output) {
	if scope.Err() != nil {
		return
	}
	attrs := map[string]interface{}{"T": T,}
	for _, a := range optional {
		a(attrs)
	}
	opspec := tf.OpSpec{
		Type: "QuantizeV2",
		Input: []tf.Input{
			input, min_range, max_range, 
		},
		Attrs: attrs,
	}
	op := scope.AddOperation(opspec)
	return op.Output(0), op.Output(1), op.Output(2)
}

// DequantizeAttr is an optional argument to Dequantize.
type DequantizeAttr func(optionalAttr)


// DequantizeMode sets the optional mode attribute to value.
// If not specified, defaults to "MIN_COMBINED" 
func DequantizeMode(value string) DequantizeAttr {
	return func(m optionalAttr) {
		m["mode"] = value
	}
}

// Dequantize the 'input' tensor into a float Tensor.
//
// [min_range, max_range] are scalar floats that specify the range for
// the 'input' data. The 'mode' attribute controls exactly which calculations are
// used to convert the float values to their quantized equivalents.
// 
// In 'MIN_COMBINED' mode, each value of the tensor will undergo the following:
// 
// ```
// if T == qint8, in[i] += (range(T) + 1)/ 2.0
// out[i] = min_range + (in[i]* (max_range - min_range) / range(T))
// ```
// here `range(T) = numeric_limits<T>::max() - numeric_limits<T>::min()`
// 
// *MIN_COMBINED Mode Example*
// 
// If the input comes from a QuantizedRelu6, the output type is
// quint8 (range of 0-255) but the possible range of QuantizedRelu6 is
// 0-6.  The min_range and max_range values are therefore 0.0 and 6.0.
// Dequantize on quint8 will take each value, cast to float, and multiply
// by 6 / 255.
// Note that if quantizedtype is qint8, the operation will additionally add
// each value by 128 prior to casting.
// 
// If the mode is 'MIN_FIRST', then this approach is used:
// 
// ```
// number_of_steps = 1 << (# of bits in T)
// range_adjust = number_of_steps / (number_of_steps - 1)
// range = (range_max - range_min) * range_adjust
// range_scale = range / number_of_steps
// const double offset_input = static_cast<double>(input) - lowest_quantized;
// result = range_min + ((input - numeric_limits<T>::min()) * range_scale)
// ```
//
// Arguments:
//	
//	min_range: The minimum scalar value possibly produced for the input.
//	max_range: The maximum scalar value possibly produced for the input.
func Dequantize(scope *Scope, input tf.Output, min_range tf.Output, max_range tf.Output, optional ...DequantizeAttr)(output tf.Output) {
	if scope.Err() != nil {
		return
	}
	attrs := map[string]interface{}{}
	for _, a := range optional {
		a(attrs)
	}
	opspec := tf.OpSpec{
		Type: "Dequantize",
		Input: []tf.Input{
			input, min_range, max_range, 
		},
		Attrs: attrs,
	}
	op := scope.AddOperation(opspec)
	return op.Output(0)
}

// FakeQuantWithMinMaxArgsAttr is an optional argument to FakeQuantWithMinMaxArgs.
type FakeQuantWithMinMaxArgsAttr func(optionalAttr)


// FakeQuantWithMinMaxArgsMin sets the optional min attribute to value.
// If not specified, defaults to -6 
func FakeQuantWithMinMaxArgsMin(value float32) FakeQuantWithMinMaxArgsAttr {
	return func(m optionalAttr) {
		m["min"] = value
	}
}

// FakeQuantWithMinMaxArgsMax sets the optional max attribute to value.
// If not specified, defaults to 6 
func FakeQuantWithMinMaxArgsMax(value float32) FakeQuantWithMinMaxArgsAttr {
	return func(m optionalAttr) {
		m["max"] = value
	}
}

// Fake-quantize the 'inputs' tensor, type float to 'outputs' tensor of same type.
//
// Attributes [min; max] define the clamping range for the 'inputs' data.  Op
// divides this range into 255 steps (total of 256 values), then replaces each
// 'inputs' value with the closest of the quantized step values.
// 
// Quantization is called fake since the output is still in floating point.
func FakeQuantWithMinMaxArgs(scope *Scope, inputs tf.Output, optional ...FakeQuantWithMinMaxArgsAttr)(outputs tf.Output) {
	if scope.Err() != nil {
		return
	}
	attrs := map[string]interface{}{}
	for _, a := range optional {
		a(attrs)
	}
	opspec := tf.OpSpec{
		Type: "FakeQuantWithMinMaxArgs",
		Input: []tf.Input{
			inputs, 
		},
		Attrs: attrs,
	}
	op := scope.AddOperation(opspec)
	return op.Output(0)
}

// FakeQuantWithMinMaxArgsGradientAttr is an optional argument to FakeQuantWithMinMaxArgsGradient.
type FakeQuantWithMinMaxArgsGradientAttr func(optionalAttr)


// FakeQuantWithMinMaxArgsGradientMin sets the optional min attribute to value.
// If not specified, defaults to -6 
func FakeQuantWithMinMaxArgsGradientMin(value float32) FakeQuantWithMinMaxArgsGradientAttr {
	return func(m optionalAttr) {
		m["min"] = value
	}
}

// FakeQuantWithMinMaxArgsGradientMax sets the optional max attribute to value.
// If not specified, defaults to 6 
func FakeQuantWithMinMaxArgsGradientMax(value float32) FakeQuantWithMinMaxArgsGradientAttr {
	return func(m optionalAttr) {
		m["max"] = value
	}
}

// Compute gradients for a FakeQuantWithMinMaxArgs operation.
//
// Arguments:
//	gradients: Backpropagated gradients above the FakeQuantWithMinMaxArgs operation.
//	inputs: Values passed as inputs to the FakeQuantWithMinMaxArgs operation.
//
// Returns Backpropagated gradients below the FakeQuantWithMinMaxArgs operation:
// `gradients * (inputs >= min && inputs <= max)`.
func FakeQuantWithMinMaxArgsGradient(scope *Scope, gradients tf.Output, inputs tf.Output, optional ...FakeQuantWithMinMaxArgsGradientAttr)(backprops tf.Output) {
	if scope.Err() != nil {
		return
	}
	attrs := map[string]interface{}{}
	for _, a := range optional {
		a(attrs)
	}
	opspec := tf.OpSpec{
		Type: "FakeQuantWithMinMaxArgsGradient",
		Input: []tf.Input{
			gradients, inputs, 
		},
		Attrs: attrs,
	}
	op := scope.AddOperation(opspec)
	return op.Output(0)
}

// QuantizedMulAttr is an optional argument to QuantizedMul.
type QuantizedMulAttr func(optionalAttr)


// QuantizedMulToutput sets the optional Toutput attribute to value.
// If not specified, defaults to DT_QINT32 
func QuantizedMulToutput(value tf.DataType) QuantizedMulAttr {
	return func(m optionalAttr) {
		m["Toutput"] = value
	}
}

// Returns x * y element-wise, working on quantized buffers.
//
// Arguments:
//	
//	
//	min_x: The float value that the lowest quantized `x` value represents.
//	max_x: The float value that the highest quantized `x` value represents.
//	min_y: The float value that the lowest quantized `y` value represents.
//	max_y: The float value that the highest quantized `y` value represents.
//
// Returns The float value that the lowest quantized output value represents.The float value that the highest quantized output value represents.
// 
// *NOTE*: `QuantizedMul` supports limited forms of broadcasting. More about
// broadcasting [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
func QuantizedMul(scope *Scope, x tf.Output, y tf.Output, min_x tf.Output, max_x tf.Output, min_y tf.Output, max_y tf.Output, optional ...QuantizedMulAttr)(z tf.Output, min_z tf.Output, max_z tf.Output) {
	if scope.Err() != nil {
		return
	}
	attrs := map[string]interface{}{}
	for _, a := range optional {
		a(attrs)
	}
	opspec := tf.OpSpec{
		Type: "QuantizedMul",
		Input: []tf.Input{
			x, y, min_x, max_x, min_y, max_y, 
		},
		Attrs: attrs,
	}
	op := scope.AddOperation(opspec)
	return op.Output(0), op.Output(1), op.Output(2)
}

// Fake-quantize the 'inputs' tensor of type float via global float scalars `min`
//
// and `max` to 'outputs' tensor of same shape as `inputs`.
// 
// [min; max] is the clamping range for the 'inputs' data.  Op divides this range
// into 255 steps (total of 256 values), then replaces each 'inputs' value with the
// closest of the quantized step values.
// 
// This operation has a gradient and thus allows for training `min` and `max` values.
func FakeQuantWithMinMaxVars(scope *Scope, inputs tf.Output, min tf.Output, max tf.Output)(outputs tf.Output) {
	if scope.Err() != nil {
		return
	}
	opspec := tf.OpSpec{
		Type: "FakeQuantWithMinMaxVars",
		Input: []tf.Input{
			inputs, min, max, 
		},
	}
	op := scope.AddOperation(opspec)
	return op.Output(0)
}
