// Copyright 2017 The TensorFlow Authors. All Rights Reserved.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// DO NOT EDIT
// This file was machine generated by github.com/ctava/tensorflow/tensorflow/go/genop/wrap
//
// WARNING: This generation of wrapper function for TensorFlow ops is in an
// experimental state. The generated API can change without notice.

package op

import tf "github.com/tensorflow/tensorflow/tensorflow/go"

// CTCLossAttr is an optional argument to CTCLoss.
type CTCLossAttr func(optionalAttr)


// CTCLossPreprocessCollapseRepeated sets the optional preprocess_collapse_repeated attribute to value.
//
// value: Scalar, if true then repeated labels are
// collapsed prior to the CTC calculation.
// If not specified, defaults to false 
func CTCLossPreprocessCollapseRepeated(value bool) CTCLossAttr {
	return func(m optionalAttr) {
		m["preprocess_collapse_repeated"] = value
	}
}

// CTCLossCtcMergeRepeated sets the optional ctc_merge_repeated attribute to value.
//
// value: Scalar.  If set to false, *during* CTC calculation
// repeated non-blank labels will not be merged and are interpreted as
// individual labels.  This is a simplified version of CTC.
// If not specified, defaults to true 
func CTCLossCtcMergeRepeated(value bool) CTCLossAttr {
	return func(m optionalAttr) {
		m["ctc_merge_repeated"] = value
	}
}

// Calculates the CTC Loss (log probability) for each batch entry.  Also calculates
//
// the gradient.  This class performs the softmax operation for you, so inputs
// should be e.g. linear projections of outputs by an LSTM.
//
// Arguments:
//	inputs: 3-D, shape: `(max_time x batch_size x num_classes)`, the logits.
//	labels_indices: The indices of a `SparseTensor<int32, 2>`.
// `labels_indices(i, :) == [b, t]` means `labels_values(i)` stores the id for
// `(batch b, time t)`.
//	labels_values: The values (labels) associated with the given batch and time.
//	sequence_length: A vector containing sequence lengths (batch).
//
// Returns A vector (batch) containing log-probabilities.The gradient of `loss`.  3-D, shape:
// `(max_time x batch_size x num_classes)`.
func CTCLoss(scope *Scope, inputs tf.Output, labels_indices tf.Output, labels_values tf.Output, sequence_length tf.Output, optional ...CTCLossAttr)(loss tf.Output, gradient tf.Output) {
	if scope.Err() != nil {
		return
	}
	attrs := map[string]interface{}{}
	for _, a := range optional {
		a(attrs)
	}
	opspec := tf.OpSpec{
		Type: "CTCLoss",
		Input: []tf.Input{
			inputs, labels_indices, labels_values, sequence_length, 
		},
		Attrs: attrs,
	}
	op := scope.AddOperation(opspec)
	return op.Output(0), op.Output(1)
}

// L2 Loss.
//
// Computes half the L2 norm of a tensor without the `sqrt`:
// 
//     output = sum(t ** 2) / 2
//
// Arguments:
//	t: Typically 2-D, but may have any dimensions.
//
// Returns 0-D.
func L2Loss(scope *Scope, t tf.Output)(output tf.Output) {
	if scope.Err() != nil {
		return
	}
	opspec := tf.OpSpec{
		Type: "L2Loss",
		Input: []tf.Input{
			t, 
		},
	}
	op := scope.AddOperation(opspec)
	return op.Output(0)
}

// CTCLossAttr is an optional argument to CTCLoss.
type CTCLossAttr func(optionalAttr)


// CTCLossPreprocessCollapseRepeated sets the optional preprocess_collapse_repeated attribute to value.
//
// value: Scalar, if true then repeated labels are
// collapsed prior to the CTC calculation.
// If not specified, defaults to false 
func CTCLossPreprocessCollapseRepeated(value bool) CTCLossAttr {
	return func(m optionalAttr) {
		m["preprocess_collapse_repeated"] = value
	}
}

// CTCLossCtcMergeRepeated sets the optional ctc_merge_repeated attribute to value.
//
// value: Scalar.  If set to false, *during* CTC calculation
// repeated non-blank labels will not be merged and are interpreted as
// individual labels.  This is a simplified version of CTC.
// If not specified, defaults to true 
func CTCLossCtcMergeRepeated(value bool) CTCLossAttr {
	return func(m optionalAttr) {
		m["ctc_merge_repeated"] = value
	}
}

// Calculates the CTC Loss (log probability) for each batch entry.  Also calculates
//
// the gradient.  This class performs the softmax operation for you, so inputs
// should be e.g. linear projections of outputs by an LSTM.
//
// Arguments:
//	inputs: 3-D, shape: `(max_time x batch_size x num_classes)`, the logits.
//	labels_indices: The indices of a `SparseTensor<int32, 2>`.
// `labels_indices(i, :) == [b, t]` means `labels_values(i)` stores the id for
// `(batch b, time t)`.
//	labels_values: The values (labels) associated with the given batch and time.
//	sequence_length: A vector containing sequence lengths (batch).
//
// Returns A vector (batch) containing log-probabilities.The gradient of `loss`.  3-D, shape:
// `(max_time x batch_size x num_classes)`.
func CTCLoss(scope *Scope, inputs tf.Output, labels_indices tf.Output, labels_values tf.Output, sequence_length tf.Output, optional ...CTCLossAttr)(loss tf.Output, gradient tf.Output) {
	if scope.Err() != nil {
		return
	}
	attrs := map[string]interface{}{}
	for _, a := range optional {
		a(attrs)
	}
	opspec := tf.OpSpec{
		Type: "CTCLoss",
		Input: []tf.Input{
			inputs, labels_indices, labels_values, sequence_length, 
		},
		Attrs: attrs,
	}
	op := scope.AddOperation(opspec)
	return op.Output(0), op.Output(1)
}

// L2 Loss.
//
// Computes half the L2 norm of a tensor without the `sqrt`:
// 
//     output = sum(t ** 2) / 2
//
// Arguments:
//	t: Typically 2-D, but may have any dimensions.
//
// Returns 0-D.
func L2Loss(scope *Scope, t tf.Output)(output tf.Output) {
	if scope.Err() != nil {
		return
	}
	opspec := tf.OpSpec{
		Type: "L2Loss",
		Input: []tf.Input{
			t, 
		},
	}
	op := scope.AddOperation(opspec)
	return op.Output(0)
}
