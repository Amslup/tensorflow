// Copyright 2017 The TensorFlow Authors. All Rights Reserved.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// DO NOT EDIT
// This file was machine generated by github.com/ctava/tensorflow/tensorflow/go/genop/wrap
//
// WARNING: This generation of wrapper function for TensorFlow ops is in an
// experimental state. The generated API can change without notice.

package op

import tf "github.com/tensorflow/tensorflow/tensorflow/go"

// DepthToSpace for tensors of type T.
//
// Rearranges data from depth into blocks of spatial data.
// This is the reverse transformation of SpaceToDepth. More specifically,
// this op outputs a copy of the input tensor where values from the `depth`
// dimension are moved in spatial blocks to the `height` and `width` dimensions.
// The attr `block_size` indicates the input block size and how the data is moved.
// 
//   * Chunks of data of size `block_size * block_size` from depth are rearranged
//     into non-overlapping blocks of size `block_size x block_size`
//   * The width the output tensor is `input_depth * block_size`, whereas the
//     height is `input_height * block_size`.
//   * The depth of the input tensor must be divisible by
//     `block_size * block_size`.
// 
// That is, assuming the input is in the shape:
// `[batch, height, width, depth]`,
// the shape of the output will be:
// `[batch, height*block_size, width*block_size, depth/(block_size*block_size)]`
// 
// This operation requires that the input tensor be of rank 4, and that
// `block_size` be >=1 and that `block_size * block_size` be a divisor of the
// input depth.
// 
// This operation is useful for resizing the activations between convolutions
// (but keeping all data), e.g. instead of pooling. It is also useful for training
// purely convolutional models.
// 
// For example, given this input of shape `[1, 1, 1, 4]`, and a block size of 2:
// 
// ```prettyprint
// x = [[[[1, 2, 3, 4]]]]
// 
// ```
// 
// This operation will output a tensor of shape `[1, 2, 2, 1]`:
// 
// ```prettyprint
//    [[[[1], [2]],
//      [[3], [4]]]]
// ```
// 
// Here, the input has a batch of 1 and each batch element has shape `[1, 1, 4]`,
// the corresponding output will have 2x2 elements and will have a depth of
// 1 channel (1 = `4 / (block_size * block_size)`).
// The output element shape is `[2, 2, 1]`.
// 
// For an input tensor with larger depth, here of shape `[1, 1, 1, 12]`, e.g.
// 
// ```prettyprint
// x = [[[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]]]]
// ```
// 
// This operation, for block size of 2, will return the following tensor of shape
// `[1, 2, 2, 3]`
// 
// ```prettyprint
//    [[[[1, 2, 3], [4, 5, 6]],
//      [[7, 8, 9], [10, 11, 12]]]]
// 
// ```
// 
// Similarly, for the following input of shape `[1 2 2 4]`, and a block size of 2:
// 
// ```prettyprint
// x =  [[[[1, 2, 3, 4],
//        [5, 6, 7, 8]],
//       [[9, 10, 11, 12],
//        [13, 14, 15, 16]]]]
// ```
// 
// the operator will return the following tensor of shape `[1 4 4 1]`:
// 
// ```prettyprint
// x = [[ [1],   [2],  [5],  [6]],
//      [ [3],   [4],  [7],  [8]],
//      [ [9],  [10], [13],  [14]],
//      [ [11], [12], [15],  [16]]]
// 
// ```
//
// Arguments:
//	
//	block_size: The size of the spatial block, same as in Space2Depth.
func DepthToSpace(scope *Scope, input tf.Output, block_size int64)(output tf.Output) {
	if scope.Err() != nil {
		return
	}
	attrs := map[string]interface{}{"block_size": block_size,}
	opspec := tf.OpSpec{
		Type: "DepthToSpace",
		Input: []tf.Input{
			input, 
		},
		Attrs: attrs,
	}
	op := scope.AddOperation(opspec)
	return op.Output(0)
}

// SpaceToDepth for tensors of type T.
//
// Rearranges blocks of spatial data, into depth. More specifically,
// this op outputs a copy of the input tensor where values from the `height`
// and `width` dimensions are moved to the `depth` dimension.
// The attr `block_size` indicates the input block size and how the data is moved.
// 
//   * Non-overlapping blocks of size `block_size x block size` are rearranged
//     into depth at each location.
//   * The depth of the output tensor is `input_depth * block_size * block_size`.
//   * The input tensor's height and width must be divisible by block_size.
// 
// That is, assuming the input is in the shape:
// `[batch, height, width, depth]`,
// the shape of the output will be:
// `[batch, height/block_size, width/block_size, depth*block_size*block_size]`
// 
// This operation requires that the input tensor be of rank 4, and that
// `block_size` be >=1 and a divisor of both the input `height` and `width`.
// 
// This operation is useful for resizing the activations between convolutions
// (but keeping all data), e.g. instead of pooling. It is also useful for training
// purely convolutional models.
// 
// For example, given this input of shape `[1, 2, 2, 1]`, and block_size of 2:
// 
// ```prettyprint
// x = [[[[1], [2]],
//       [[3], [4]]]]
// ```
// 
// This operation will output a tensor of shape `[1, 1, 1, 4]`:
// 
// ```prettyprint
// [[[[1, 2, 3, 4]]]]
// ```
// 
// Here, the input has a batch of 1 and each batch element has shape `[2, 2, 1]`,
// the corresponding output will have a single element (i.e. width and height are
// both 1) and will have a depth of 4 channels (1 * block_size * block_size).
// The output element shape is `[1, 1, 4]`.
// 
// For an input tensor with larger depth, here of shape `[1, 2, 2, 3]`, e.g.
// 
// ```prettyprint
// x = [[[[1, 2, 3], [4, 5, 6]],
//       [[7, 8, 9], [10, 11, 12]]]]
// ```
// 
// This operation, for block_size of 2, will return the following tensor of shape
// `[1, 1, 1, 12]`
// 
// ```prettyprint
// [[[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]]]]
// ```
// 
// Similarly, for the following input of shape `[1 4 4 1]`, and a block size of 2:
// 
// ```prettyprint
// x = [[[[1],   [2],  [5],  [6]],
//       [[3],   [4],  [7],  [8]],
//       [[9],  [10], [13],  [14]],
//       [[11], [12], [15],  [16]]]]
// ```
// 
// the operator will return the following tensor of shape `[1 2 2 4]`:
// 
// ```prettyprint
// x = [[[[1, 2, 3, 4],
//        [5, 6, 7, 8]],
//       [[9, 10, 11, 12],
//        [13, 14, 15, 16]]]]
// ```
//
// Arguments:
//	
//	block_size: The size of the spatial block.
func SpaceToDepth(scope *Scope, input tf.Output, block_size int64)(output tf.Output) {
	if scope.Err() != nil {
		return
	}
	attrs := map[string]interface{}{"block_size": block_size,}
	opspec := tf.OpSpec{
		Type: "SpaceToDepth",
		Input: []tf.Input{
			input, 
		},
		Attrs: attrs,
	}
	op := scope.AddOperation(opspec)
	return op.Output(0)
}

// BatchToSpace for 4-D tensors of type T.
//
// This is a legacy version of the more general BatchToSpaceND.
// 
// Rearranges (permutes) data from batch into blocks of spatial data, followed by
// cropping. This is the reverse transformation of SpaceToBatch. More specifically,
// this op outputs a copy of the input tensor where values from the `batch`
// dimension are moved in spatial blocks to the `height` and `width` dimensions,
// followed by cropping along the `height` and `width` dimensions.
//
// Arguments:
//	input: 4-D tensor with shape
// `[batch*block_size*block_size, height_pad/block_size, width_pad/block_size,
//   depth]`. Note that the batch size of the input tensor must be divisible by
// `block_size * block_size`.
//	crops: 2-D tensor of non-negative integers with shape `[2, 2]`. It specifies
// how many elements to crop from the intermediate result across the spatial
// dimensions as follows:
// 
//     crops = [[crop_top, crop_bottom], [crop_left, crop_right]]
//	
//
// Returns 4-D with shape `[batch, height, width, depth]`, where:
// 
//       height = height_pad - crop_top - crop_bottom
//       width = width_pad - crop_left - crop_right
// 
// The attr `block_size` must be greater than one. It indicates the block size.
// 
// Some examples:
// 
// (1) For the following input of shape `[4, 1, 1, 1]` and block_size of 2:
// 
// ```prettyprint
// [[[[1]]], [[[2]]], [[[3]]], [[[4]]]]
// ```
// 
// The output tensor has shape `[1, 2, 2, 1]` and value:
// 
// ```prettyprint
// x = [[[[1], [2]], [[3], [4]]]]
// ```
// 
// (2) For the following input of shape `[4, 1, 1, 3]` and block_size of 2:
// 
// ```prettyprint
// [[[1, 2, 3]], [[4, 5, 6]], [[7, 8, 9]], [[10, 11, 12]]]
// ```
// 
// The output tensor has shape `[1, 2, 2, 3]` and value:
// 
// ```prettyprint
// x = [[[[1, 2, 3], [4, 5, 6]],
//       [[7, 8, 9], [10, 11, 12]]]]
// ```
// 
// (3) For the following input of shape `[4, 2, 2, 1]` and block_size of 2:
// 
// ```prettyprint
// x = [[[[1], [3]], [[9], [11]]],
//      [[[2], [4]], [[10], [12]]],
//      [[[5], [7]], [[13], [15]]],
//      [[[6], [8]], [[14], [16]]]]
// ```
// 
// The output tensor has shape `[1, 4, 4, 1]` and value:
// 
// ```prettyprint
// x = [[[1],   [2],  [3],  [4]],
//      [[5],   [6],  [7],  [8]],
//      [[9],  [10], [11],  [12]],
//      [[13], [14], [15],  [16]]]
// ```
// 
// (4) For the following input of shape `[8, 1, 2, 1]` and block_size of 2:
// 
// ```prettyprint
// x = [[[[1], [3]]], [[[9], [11]]], [[[2], [4]]], [[[10], [12]]],
//      [[[5], [7]]], [[[13], [15]]], [[[6], [8]]], [[[14], [16]]]]
// ```
// 
// The output tensor has shape `[2, 2, 4, 1]` and value:
// 
// ```prettyprint
// x = [[[[1], [3]], [[5], [7]]],
//      [[[2], [4]], [[10], [12]]],
//      [[[5], [7]], [[13], [15]]],
//      [[[6], [8]], [[14], [16]]]]
// ```
func BatchToSpace(scope *Scope, input tf.Output, crops tf.Output, block_size int64)(output tf.Output) {
	if scope.Err() != nil {
		return
	}
	attrs := map[string]interface{}{"block_size": block_size,}
	opspec := tf.OpSpec{
		Type: "BatchToSpace",
		Input: []tf.Input{
			input, crops, 
		},
		Attrs: attrs,
	}
	op := scope.AddOperation(opspec)
	return op.Output(0)
}

// SpaceToBatch for 4-D tensors of type T.
//
// This is a legacy version of the more general SpaceToBatchND.
// 
// Zero-pads and then rearranges (permutes) blocks of spatial data into batch.
// More specifically, this op outputs a copy of the input tensor where values from
// the `height` and `width` dimensions are moved to the `batch` dimension. After
// the zero-padding, both `height` and `width` of the input must be divisible by the
// block size.
//
// Arguments:
//	input: 4-D with shape `[batch, height, width, depth]`.
//	paddings: 2-D tensor of non-negative integers with shape `[2, 2]`. It specifies
//   the padding of the input with zeros across the spatial dimensions as follows:
// 
//       paddings = [[pad_top, pad_bottom], [pad_left, pad_right]]
// 
//   The effective spatial dimensions of the zero-padded input tensor will be:
// 
//       height_pad = pad_top + height + pad_bottom
//       width_pad = pad_left + width + pad_right
// 
// The attr `block_size` must be greater than one. It indicates the block size.
// 
//   * Non-overlapping blocks of size `block_size x block size` in the height and
//     width dimensions are rearranged into the batch dimension at each location.
//   * The batch of the output tensor is `batch * block_size * block_size`.
//   * Both height_pad and width_pad must be divisible by block_size.
// 
// The shape of the output will be:
// 
//     [batch*block_size*block_size, height_pad/block_size, width_pad/block_size,
//      depth]
// 
// Some examples:
// 
// (1) For the following input of shape `[1, 2, 2, 1]` and block_size of 2:
// 
// ```prettyprint
// x = [[[[1], [2]], [[3], [4]]]]
// ```
// 
// The output tensor has shape `[4, 1, 1, 1]` and value:
// 
// ```prettyprint
// [[[[1]]], [[[2]]], [[[3]]], [[[4]]]]
// ```
// 
// (2) For the following input of shape `[1, 2, 2, 3]` and block_size of 2:
// 
// ```prettyprint
// x = [[[[1, 2, 3], [4, 5, 6]],
//       [[7, 8, 9], [10, 11, 12]]]]
// ```
// 
// The output tensor has shape `[4, 1, 1, 3]` and value:
// 
// ```prettyprint
// [[[1, 2, 3]], [[4, 5, 6]], [[7, 8, 9]], [[10, 11, 12]]]
// ```
// 
// (3) For the following input of shape `[1, 4, 4, 1]` and block_size of 2:
// 
// ```prettyprint
// x = [[[[1],   [2],  [3],  [4]],
//       [[5],   [6],  [7],  [8]],
//       [[9],  [10], [11],  [12]],
//       [[13], [14], [15],  [16]]]]
// ```
// 
// The output tensor has shape `[4, 2, 2, 1]` and value:
// 
// ```prettyprint
// x = [[[[1], [3]], [[9], [11]]],
//      [[[2], [4]], [[10], [12]]],
//      [[[5], [7]], [[13], [15]]],
//      [[[6], [8]], [[14], [16]]]]
// ```
// 
// (4) For the following input of shape `[2, 2, 4, 1]` and block_size of 2:
// 
// ```prettyprint
// x = [[[[1],   [2],  [3],  [4]],
//       [[5],   [6],  [7],  [8]]],
//      [[[9],  [10], [11],  [12]],
//       [[13], [14], [15],  [16]]]]
// ```
// 
// The output tensor has shape `[8, 1, 2, 1]` and value:
// 
// ```prettyprint
// x = [[[[1], [3]]], [[[9], [11]]], [[[2], [4]]], [[[10], [12]]],
//      [[[5], [7]]], [[[13], [15]]], [[[6], [8]]], [[[14], [16]]]]
// ```
// 
// Among others, this operation is useful for reducing atrous convolution into
// regular convolution.
//	
func SpaceToBatch(scope *Scope, input tf.Output, paddings tf.Output, block_size int64)(output tf.Output) {
	if scope.Err() != nil {
		return
	}
	attrs := map[string]interface{}{"block_size": block_size,}
	opspec := tf.OpSpec{
		Type: "SpaceToBatch",
		Input: []tf.Input{
			input, paddings, 
		},
		Attrs: attrs,
	}
	op := scope.AddOperation(opspec)
	return op.Output(0)
}

// BatchToSpace for N-D tensors of type T.
//
// This operation reshapes the "batch" dimension 0 into `M + 1` dimensions of shape
// `block_shape + [batch]`, interleaves these blocks back into the grid defined by
// the spatial dimensions `[1, ..., M]`, to obtain a result with the same rank as
// the input.  The spatial dimensions of this intermediate result are then
// optionally cropped according to `crops` to produce the output.  This is the
// reverse of SpaceToBatch.  See below for a precise description.
//
// Arguments:
//	input: N-D with shape `input_shape = [batch] + spatial_shape + remaining_shape`,
// where spatial_shape has M dimensions.
//	block_shape: 1-D with shape `[M]`, all values must be >= 1.
//	crops: 2-D with shape `[M, 2]`, all values must be >= 0.
//   `crops[i] = [crop_start, crop_end]` specifies the amount to crop from input
//   dimension `i + 1`, which corresponds to spatial dimension `i`.  It is
//   required that
//   `crop_start[i] + crop_end[i] <= block_shape[i] * input_shape[i + 1]`.
// 
// This operation is equivalent to the following steps:
// 
// 1. Reshape `input` to `reshaped` of shape:
//      [block_shape[0], ..., block_shape[M-1],
//       batch / prod(block_shape),
//       input_shape[1], ..., input_shape[N-1]]
// 
// 2. Permute dimensions of `reshaped` to produce `permuted` of shape
//      [batch / prod(block_shape),
// 
//       input_shape[1], block_shape[0],
//       ...,
//       input_shape[M], block_shape[M-1],
// 
//       input_shape[M+1], ..., input_shape[N-1]]
// 
// 3. Reshape `permuted` to produce `reshaped_permuted` of shape
//      [batch / prod(block_shape),
// 
//       input_shape[1] * block_shape[0],
//       ...,
//       input_shape[M] * block_shape[M-1],
// 
//       input_shape[M+1],
//       ...,
//       input_shape[N-1]]
// 
// 4. Crop the start and end of dimensions `[1, ..., M]` of
//    `reshaped_permuted` according to `crops` to produce the output of shape:
//      [batch / prod(block_shape),
// 
//       input_shape[1] * block_shape[0] - crops[0,0] - crops[0,1],
//       ...,
//       input_shape[M] * block_shape[M-1] - crops[M-1,0] - crops[M-1,1],
// 
//       input_shape[M+1], ..., input_shape[N-1]]
// 
// Some examples:
// 
// (1) For the following input of shape `[4, 1, 1, 1]`, `block_shape = [2, 2]`, and
//     `crops = [[0, 0], [0, 0]]`:
// 
// ```prettyprint
// [[[[1]]], [[[2]]], [[[3]]], [[[4]]]]
// ```
// 
// The output tensor has shape `[1, 2, 2, 1]` and value:
// 
// ```prettyprint
// x = [[[[1], [2]], [[3], [4]]]]
// ```
// 
// (2) For the following input of shape `[4, 1, 1, 3]`, `block_shape = [2, 2]`, and
//     `crops = [[0, 0], [0, 0]]`:
// 
// ```prettyprint
// [[[1, 2, 3]], [[4, 5, 6]], [[7, 8, 9]], [[10, 11, 12]]]
// ```
// 
// The output tensor has shape `[1, 2, 2, 3]` and value:
// 
// ```prettyprint
// x = [[[[1, 2, 3], [4, 5, 6]],
//       [[7, 8, 9], [10, 11, 12]]]]
// ```
// 
// (3) For the following input of shape `[4, 2, 2, 1]`, `block_shape = [2, 2]`, and
//     `crops = [[0, 0], [0, 0]]`:
// 
// ```prettyprint
// x = [[[[1], [3]], [[9], [11]]],
//      [[[2], [4]], [[10], [12]]],
//      [[[5], [7]], [[13], [15]]],
//      [[[6], [8]], [[14], [16]]]]
// ```
// 
// The output tensor has shape `[1, 4, 4, 1]` and value:
// 
// ```prettyprint
// x = [[[1],   [2],  [3],  [4]],
//      [[5],   [6],  [7],  [8]],
//      [[9],  [10], [11],  [12]],
//      [[13], [14], [15],  [16]]]
// ```
// 
// (4) For the following input of shape `[8, 1, 3, 1]`, `block_shape = [2, 2]`, and
//     `crops = [[0, 0], [2, 0]]`:
// 
// ```prettyprint
// x = [[[[0], [1], [3]]], [[[0], [9], [11]]],
//      [[[0], [2], [4]]], [[[0], [10], [12]]],
//      [[[0], [5], [7]]], [[[0], [13], [15]]],
//      [[[0], [6], [8]]], [[[0], [14], [16]]]]
// ```
// 
// The output tensor has shape `[2, 2, 4, 1]` and value:
// 
// ```prettyprint
// x = [[[[1],   [2],  [3],  [4]],
//       [[5],   [6],  [7],  [8]]],
//      [[[9],  [10], [11],  [12]],
//       [[13], [14], [15],  [16]]]]
// ```
func BatchToSpaceND(scope *Scope, input tf.Output, block_shape tf.Output, crops tf.Output)(output tf.Output) {
	if scope.Err() != nil {
		return
	}
	opspec := tf.OpSpec{
		Type: "BatchToSpaceND",
		Input: []tf.Input{
			input, block_shape, crops, 
		},
	}
	op := scope.AddOperation(opspec)
	return op.Output(0)
}

// SpaceToBatch for N-D tensors of type T.
//
// This operation divides "spatial" dimensions `[1, ..., M]` of the input into a
// grid of blocks of shape `block_shape`, and interleaves these blocks with the
// "batch" dimension (0) such that in the output, the spatial dimensions
// `[1, ..., M]` correspond to the position within the grid, and the batch
// dimension combines both the position within a spatial block and the original
// batch position.  Prior to division into blocks, the spatial dimensions of the
// input are optionally zero padded according to `paddings`.  See below for a
// precise description.
//
// Arguments:
//	input: N-D with shape `input_shape = [batch] + spatial_shape + remaining_shape`,
// where spatial_shape has `M` dimensions.
//	block_shape: 1-D with shape `[M]`, all values must be >= 1.
//	paddings: 2-D with shape `[M, 2]`, all values must be >= 0.
//   `paddings[i] = [pad_start, pad_end]` specifies the padding for input dimension
//   `i + 1`, which corresponds to spatial dimension `i`.  It is required that
//   `block_shape[i]` divides `input_shape[i + 1] + pad_start + pad_end`.
// 
// This operation is equivalent to the following steps:
// 
// 1. Zero-pad the start and end of dimensions `[1, ..., M]` of the
//    input according to `paddings` to produce `padded` of shape `padded_shape`.
// 
// 2. Reshape `padded` to `reshaped_padded` of shape:
// 
//      [batch] +
//      [padded_shape[1] / block_shape[0],
//        block_shape[0],
//       ...,
//       padded_shape[M] / block_shape[M-1],
//       block_shape[M-1]] +
//      remaining_shape
// 
// 3. Permute dimensions of `reshaped_padded` to produce
//    `permuted_reshaped_padded` of shape:
// 
//      block_shape +
//      [batch] +
//      [padded_shape[1] / block_shape[0],
//       ...,
//       padded_shape[M] / block_shape[M-1]] +
//      remaining_shape
// 
// 4. Reshape `permuted_reshaped_padded` to flatten `block_shape` into the batch
//    dimension, producing an output tensor of shape:
// 
//      [batch * prod(block_shape)] +
//      [padded_shape[1] / block_shape[0],
//       ...,
//       padded_shape[M] / block_shape[M-1]] +
//      remaining_shape
// 
// Some examples:
// 
// (1) For the following input of shape `[1, 2, 2, 1]`, `block_shape = [2, 2]`, and
//     `paddings = [[0, 0], [0, 0]]`:
// 
// ```prettyprint
// x = [[[[1], [2]], [[3], [4]]]]
// ```
// 
// The output tensor has shape `[4, 1, 1, 1]` and value:
// 
// ```prettyprint
// [[[[1]]], [[[2]]], [[[3]]], [[[4]]]]
// ```
// 
// (2) For the following input of shape `[1, 2, 2, 3]`, `block_shape = [2, 2]`, and
//     `paddings = [[0, 0], [0, 0]]`:
// 
// ```prettyprint
// x = [[[[1, 2, 3], [4, 5, 6]],
//       [[7, 8, 9], [10, 11, 12]]]]
// ```
// 
// The output tensor has shape `[4, 1, 1, 3]` and value:
// 
// ```prettyprint
// [[[1, 2, 3]], [[4, 5, 6]], [[7, 8, 9]], [[10, 11, 12]]]
// ```
// 
// (3) For the following input of shape `[1, 4, 4, 1]`, `block_shape = [2, 2]`, and
//     `paddings = [[0, 0], [0, 0]]`:
// 
// ```prettyprint
// x = [[[[1],   [2],  [3],  [4]],
//       [[5],   [6],  [7],  [8]],
//       [[9],  [10], [11],  [12]],
//       [[13], [14], [15],  [16]]]]
// ```
// 
// The output tensor has shape `[4, 2, 2, 1]` and value:
// 
// ```prettyprint
// x = [[[[1], [3]], [[9], [11]]],
//      [[[2], [4]], [[10], [12]]],
//      [[[5], [7]], [[13], [15]]],
//      [[[6], [8]], [[14], [16]]]]
// ```
// 
// (4) For the following input of shape `[2, 2, 4, 1]`, block_shape = `[2, 2]`, and
//     paddings = `[[0, 0], [2, 0]]`:
// 
// ```prettyprint
// x = [[[[1],   [2],  [3],  [4]],
//       [[5],   [6],  [7],  [8]]],
//      [[[9],  [10], [11],  [12]],
//       [[13], [14], [15],  [16]]]]
// ```
// 
// The output tensor has shape `[8, 1, 3, 1]` and value:
// 
// ```prettyprint
// x = [[[[0], [1], [3]]], [[[0], [9], [11]]],
//      [[[0], [2], [4]]], [[[0], [10], [12]]],
//      [[[0], [5], [7]]], [[[0], [13], [15]]],
//      [[[0], [6], [8]]], [[[0], [14], [16]]]]
// ```
// 
// Among others, this operation is useful for reducing atrous convolution into
// regular convolution.
func SpaceToBatchND(scope *Scope, input tf.Output, block_shape tf.Output, paddings tf.Output)(output tf.Output) {
	if scope.Err() != nil {
		return
	}
	opspec := tf.OpSpec{
		Type: "SpaceToBatchND",
		Input: []tf.Input{
			input, block_shape, paddings, 
		},
	}
	op := scope.AddOperation(opspec)
	return op.Output(0)
}

// Generates values in an interval.
//
// A sequence of `num` evenly-spaced values are generated beginning at `start`.
// If `num > 1`, the values in the sequence increase by `stop - start / num - 1`,
// so that the last one is exactly `stop`.
// 
// For example:
// 
// ```
// tf.linspace(10.0, 12.0, 3, name="linspace") => [ 10.0  11.0  12.0]
// ```
//
// Arguments:
//	start: First entry in the range.
//	stop: Last entry in the range.
//	num: Number of values to generate.
//
// Returns 1-D. The generated values.
func LinSpace(scope *Scope, start tf.Output, stop tf.Output, num tf.Output)(output tf.Output) {
	if scope.Err() != nil {
		return
	}
	opspec := tf.OpSpec{
		Type: "LinSpace",
		Input: []tf.Input{
			start, stop, num, 
		},
	}
	op := scope.AddOperation(opspec)
	return op.Output(0)
}

// DepthToSpace for tensors of type T.
//
// Rearranges data from depth into blocks of spatial data.
// This is the reverse transformation of SpaceToDepth. More specifically,
// this op outputs a copy of the input tensor where values from the `depth`
// dimension are moved in spatial blocks to the `height` and `width` dimensions.
// The attr `block_size` indicates the input block size and how the data is moved.
// 
//   * Chunks of data of size `block_size * block_size` from depth are rearranged
//     into non-overlapping blocks of size `block_size x block_size`
//   * The width the output tensor is `input_depth * block_size`, whereas the
//     height is `input_height * block_size`.
//   * The depth of the input tensor must be divisible by
//     `block_size * block_size`.
// 
// That is, assuming the input is in the shape:
// `[batch, height, width, depth]`,
// the shape of the output will be:
// `[batch, height*block_size, width*block_size, depth/(block_size*block_size)]`
// 
// This operation requires that the input tensor be of rank 4, and that
// `block_size` be >=1 and that `block_size * block_size` be a divisor of the
// input depth.
// 
// This operation is useful for resizing the activations between convolutions
// (but keeping all data), e.g. instead of pooling. It is also useful for training
// purely convolutional models.
// 
// For example, given this input of shape `[1, 1, 1, 4]`, and a block size of 2:
// 
// ```prettyprint
// x = [[[[1, 2, 3, 4]]]]
// 
// ```
// 
// This operation will output a tensor of shape `[1, 2, 2, 1]`:
// 
// ```prettyprint
//    [[[[1], [2]],
//      [[3], [4]]]]
// ```
// 
// Here, the input has a batch of 1 and each batch element has shape `[1, 1, 4]`,
// the corresponding output will have 2x2 elements and will have a depth of
// 1 channel (1 = `4 / (block_size * block_size)`).
// The output element shape is `[2, 2, 1]`.
// 
// For an input tensor with larger depth, here of shape `[1, 1, 1, 12]`, e.g.
// 
// ```prettyprint
// x = [[[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]]]]
// ```
// 
// This operation, for block size of 2, will return the following tensor of shape
// `[1, 2, 2, 3]`
// 
// ```prettyprint
//    [[[[1, 2, 3], [4, 5, 6]],
//      [[7, 8, 9], [10, 11, 12]]]]
// 
// ```
// 
// Similarly, for the following input of shape `[1 2 2 4]`, and a block size of 2:
// 
// ```prettyprint
// x =  [[[[1, 2, 3, 4],
//        [5, 6, 7, 8]],
//       [[9, 10, 11, 12],
//        [13, 14, 15, 16]]]]
// ```
// 
// the operator will return the following tensor of shape `[1 4 4 1]`:
// 
// ```prettyprint
// x = [[ [1],   [2],  [5],  [6]],
//      [ [3],   [4],  [7],  [8]],
//      [ [9],  [10], [13],  [14]],
//      [ [11], [12], [15],  [16]]]
// 
// ```
//
// Arguments:
//	
//	block_size: The size of the spatial block, same as in Space2Depth.
func DepthToSpace(scope *Scope, input tf.Output, block_size int64)(output tf.Output) {
	if scope.Err() != nil {
		return
	}
	attrs := map[string]interface{}{"block_size": block_size,}
	opspec := tf.OpSpec{
		Type: "DepthToSpace",
		Input: []tf.Input{
			input, 
		},
		Attrs: attrs,
	}
	op := scope.AddOperation(opspec)
	return op.Output(0)
}

// SpaceToDepth for tensors of type T.
//
// Rearranges blocks of spatial data, into depth. More specifically,
// this op outputs a copy of the input tensor where values from the `height`
// and `width` dimensions are moved to the `depth` dimension.
// The attr `block_size` indicates the input block size and how the data is moved.
// 
//   * Non-overlapping blocks of size `block_size x block size` are rearranged
//     into depth at each location.
//   * The depth of the output tensor is `input_depth * block_size * block_size`.
//   * The input tensor's height and width must be divisible by block_size.
// 
// That is, assuming the input is in the shape:
// `[batch, height, width, depth]`,
// the shape of the output will be:
// `[batch, height/block_size, width/block_size, depth*block_size*block_size]`
// 
// This operation requires that the input tensor be of rank 4, and that
// `block_size` be >=1 and a divisor of both the input `height` and `width`.
// 
// This operation is useful for resizing the activations between convolutions
// (but keeping all data), e.g. instead of pooling. It is also useful for training
// purely convolutional models.
// 
// For example, given this input of shape `[1, 2, 2, 1]`, and block_size of 2:
// 
// ```prettyprint
// x = [[[[1], [2]],
//       [[3], [4]]]]
// ```
// 
// This operation will output a tensor of shape `[1, 1, 1, 4]`:
// 
// ```prettyprint
// [[[[1, 2, 3, 4]]]]
// ```
// 
// Here, the input has a batch of 1 and each batch element has shape `[2, 2, 1]`,
// the corresponding output will have a single element (i.e. width and height are
// both 1) and will have a depth of 4 channels (1 * block_size * block_size).
// The output element shape is `[1, 1, 4]`.
// 
// For an input tensor with larger depth, here of shape `[1, 2, 2, 3]`, e.g.
// 
// ```prettyprint
// x = [[[[1, 2, 3], [4, 5, 6]],
//       [[7, 8, 9], [10, 11, 12]]]]
// ```
// 
// This operation, for block_size of 2, will return the following tensor of shape
// `[1, 1, 1, 12]`
// 
// ```prettyprint
// [[[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]]]]
// ```
// 
// Similarly, for the following input of shape `[1 4 4 1]`, and a block size of 2:
// 
// ```prettyprint
// x = [[[[1],   [2],  [5],  [6]],
//       [[3],   [4],  [7],  [8]],
//       [[9],  [10], [13],  [14]],
//       [[11], [12], [15],  [16]]]]
// ```
// 
// the operator will return the following tensor of shape `[1 2 2 4]`:
// 
// ```prettyprint
// x = [[[[1, 2, 3, 4],
//        [5, 6, 7, 8]],
//       [[9, 10, 11, 12],
//        [13, 14, 15, 16]]]]
// ```
//
// Arguments:
//	
//	block_size: The size of the spatial block.
func SpaceToDepth(scope *Scope, input tf.Output, block_size int64)(output tf.Output) {
	if scope.Err() != nil {
		return
	}
	attrs := map[string]interface{}{"block_size": block_size,}
	opspec := tf.OpSpec{
		Type: "SpaceToDepth",
		Input: []tf.Input{
			input, 
		},
		Attrs: attrs,
	}
	op := scope.AddOperation(opspec)
	return op.Output(0)
}

// BatchToSpace for 4-D tensors of type T.
//
// This is a legacy version of the more general BatchToSpaceND.
// 
// Rearranges (permutes) data from batch into blocks of spatial data, followed by
// cropping. This is the reverse transformation of SpaceToBatch. More specifically,
// this op outputs a copy of the input tensor where values from the `batch`
// dimension are moved in spatial blocks to the `height` and `width` dimensions,
// followed by cropping along the `height` and `width` dimensions.
//
// Arguments:
//	input: 4-D tensor with shape
// `[batch*block_size*block_size, height_pad/block_size, width_pad/block_size,
//   depth]`. Note that the batch size of the input tensor must be divisible by
// `block_size * block_size`.
//	crops: 2-D tensor of non-negative integers with shape `[2, 2]`. It specifies
// how many elements to crop from the intermediate result across the spatial
// dimensions as follows:
// 
//     crops = [[crop_top, crop_bottom], [crop_left, crop_right]]
//	
//
// Returns 4-D with shape `[batch, height, width, depth]`, where:
// 
//       height = height_pad - crop_top - crop_bottom
//       width = width_pad - crop_left - crop_right
// 
// The attr `block_size` must be greater than one. It indicates the block size.
// 
// Some examples:
// 
// (1) For the following input of shape `[4, 1, 1, 1]` and block_size of 2:
// 
// ```prettyprint
// [[[[1]]], [[[2]]], [[[3]]], [[[4]]]]
// ```
// 
// The output tensor has shape `[1, 2, 2, 1]` and value:
// 
// ```prettyprint
// x = [[[[1], [2]], [[3], [4]]]]
// ```
// 
// (2) For the following input of shape `[4, 1, 1, 3]` and block_size of 2:
// 
// ```prettyprint
// [[[1, 2, 3]], [[4, 5, 6]], [[7, 8, 9]], [[10, 11, 12]]]
// ```
// 
// The output tensor has shape `[1, 2, 2, 3]` and value:
// 
// ```prettyprint
// x = [[[[1, 2, 3], [4, 5, 6]],
//       [[7, 8, 9], [10, 11, 12]]]]
// ```
// 
// (3) For the following input of shape `[4, 2, 2, 1]` and block_size of 2:
// 
// ```prettyprint
// x = [[[[1], [3]], [[9], [11]]],
//      [[[2], [4]], [[10], [12]]],
//      [[[5], [7]], [[13], [15]]],
//      [[[6], [8]], [[14], [16]]]]
// ```
// 
// The output tensor has shape `[1, 4, 4, 1]` and value:
// 
// ```prettyprint
// x = [[[1],   [2],  [3],  [4]],
//      [[5],   [6],  [7],  [8]],
//      [[9],  [10], [11],  [12]],
//      [[13], [14], [15],  [16]]]
// ```
// 
// (4) For the following input of shape `[8, 1, 2, 1]` and block_size of 2:
// 
// ```prettyprint
// x = [[[[1], [3]]], [[[9], [11]]], [[[2], [4]]], [[[10], [12]]],
//      [[[5], [7]]], [[[13], [15]]], [[[6], [8]]], [[[14], [16]]]]
// ```
// 
// The output tensor has shape `[2, 2, 4, 1]` and value:
// 
// ```prettyprint
// x = [[[[1], [3]], [[5], [7]]],
//      [[[2], [4]], [[10], [12]]],
//      [[[5], [7]], [[13], [15]]],
//      [[[6], [8]], [[14], [16]]]]
// ```
func BatchToSpace(scope *Scope, input tf.Output, crops tf.Output, block_size int64)(output tf.Output) {
	if scope.Err() != nil {
		return
	}
	attrs := map[string]interface{}{"block_size": block_size,}
	opspec := tf.OpSpec{
		Type: "BatchToSpace",
		Input: []tf.Input{
			input, crops, 
		},
		Attrs: attrs,
	}
	op := scope.AddOperation(opspec)
	return op.Output(0)
}

// SpaceToBatch for 4-D tensors of type T.
//
// This is a legacy version of the more general SpaceToBatchND.
// 
// Zero-pads and then rearranges (permutes) blocks of spatial data into batch.
// More specifically, this op outputs a copy of the input tensor where values from
// the `height` and `width` dimensions are moved to the `batch` dimension. After
// the zero-padding, both `height` and `width` of the input must be divisible by the
// block size.
//
// Arguments:
//	input: 4-D with shape `[batch, height, width, depth]`.
//	paddings: 2-D tensor of non-negative integers with shape `[2, 2]`. It specifies
//   the padding of the input with zeros across the spatial dimensions as follows:
// 
//       paddings = [[pad_top, pad_bottom], [pad_left, pad_right]]
// 
//   The effective spatial dimensions of the zero-padded input tensor will be:
// 
//       height_pad = pad_top + height + pad_bottom
//       width_pad = pad_left + width + pad_right
// 
// The attr `block_size` must be greater than one. It indicates the block size.
// 
//   * Non-overlapping blocks of size `block_size x block size` in the height and
//     width dimensions are rearranged into the batch dimension at each location.
//   * The batch of the output tensor is `batch * block_size * block_size`.
//   * Both height_pad and width_pad must be divisible by block_size.
// 
// The shape of the output will be:
// 
//     [batch*block_size*block_size, height_pad/block_size, width_pad/block_size,
//      depth]
// 
// Some examples:
// 
// (1) For the following input of shape `[1, 2, 2, 1]` and block_size of 2:
// 
// ```prettyprint
// x = [[[[1], [2]], [[3], [4]]]]
// ```
// 
// The output tensor has shape `[4, 1, 1, 1]` and value:
// 
// ```prettyprint
// [[[[1]]], [[[2]]], [[[3]]], [[[4]]]]
// ```
// 
// (2) For the following input of shape `[1, 2, 2, 3]` and block_size of 2:
// 
// ```prettyprint
// x = [[[[1, 2, 3], [4, 5, 6]],
//       [[7, 8, 9], [10, 11, 12]]]]
// ```
// 
// The output tensor has shape `[4, 1, 1, 3]` and value:
// 
// ```prettyprint
// [[[1, 2, 3]], [[4, 5, 6]], [[7, 8, 9]], [[10, 11, 12]]]
// ```
// 
// (3) For the following input of shape `[1, 4, 4, 1]` and block_size of 2:
// 
// ```prettyprint
// x = [[[[1],   [2],  [3],  [4]],
//       [[5],   [6],  [7],  [8]],
//       [[9],  [10], [11],  [12]],
//       [[13], [14], [15],  [16]]]]
// ```
// 
// The output tensor has shape `[4, 2, 2, 1]` and value:
// 
// ```prettyprint
// x = [[[[1], [3]], [[9], [11]]],
//      [[[2], [4]], [[10], [12]]],
//      [[[5], [7]], [[13], [15]]],
//      [[[6], [8]], [[14], [16]]]]
// ```
// 
// (4) For the following input of shape `[2, 2, 4, 1]` and block_size of 2:
// 
// ```prettyprint
// x = [[[[1],   [2],  [3],  [4]],
//       [[5],   [6],  [7],  [8]]],
//      [[[9],  [10], [11],  [12]],
//       [[13], [14], [15],  [16]]]]
// ```
// 
// The output tensor has shape `[8, 1, 2, 1]` and value:
// 
// ```prettyprint
// x = [[[[1], [3]]], [[[9], [11]]], [[[2], [4]]], [[[10], [12]]],
//      [[[5], [7]]], [[[13], [15]]], [[[6], [8]]], [[[14], [16]]]]
// ```
// 
// Among others, this operation is useful for reducing atrous convolution into
// regular convolution.
//	
func SpaceToBatch(scope *Scope, input tf.Output, paddings tf.Output, block_size int64)(output tf.Output) {
	if scope.Err() != nil {
		return
	}
	attrs := map[string]interface{}{"block_size": block_size,}
	opspec := tf.OpSpec{
		Type: "SpaceToBatch",
		Input: []tf.Input{
			input, paddings, 
		},
		Attrs: attrs,
	}
	op := scope.AddOperation(opspec)
	return op.Output(0)
}

// BatchToSpace for N-D tensors of type T.
//
// This operation reshapes the "batch" dimension 0 into `M + 1` dimensions of shape
// `block_shape + [batch]`, interleaves these blocks back into the grid defined by
// the spatial dimensions `[1, ..., M]`, to obtain a result with the same rank as
// the input.  The spatial dimensions of this intermediate result are then
// optionally cropped according to `crops` to produce the output.  This is the
// reverse of SpaceToBatch.  See below for a precise description.
//
// Arguments:
//	input: N-D with shape `input_shape = [batch] + spatial_shape + remaining_shape`,
// where spatial_shape has M dimensions.
//	block_shape: 1-D with shape `[M]`, all values must be >= 1.
//	crops: 2-D with shape `[M, 2]`, all values must be >= 0.
//   `crops[i] = [crop_start, crop_end]` specifies the amount to crop from input
//   dimension `i + 1`, which corresponds to spatial dimension `i`.  It is
//   required that
//   `crop_start[i] + crop_end[i] <= block_shape[i] * input_shape[i + 1]`.
// 
// This operation is equivalent to the following steps:
// 
// 1. Reshape `input` to `reshaped` of shape:
//      [block_shape[0], ..., block_shape[M-1],
//       batch / prod(block_shape),
//       input_shape[1], ..., input_shape[N-1]]
// 
// 2. Permute dimensions of `reshaped` to produce `permuted` of shape
//      [batch / prod(block_shape),
// 
//       input_shape[1], block_shape[0],
//       ...,
//       input_shape[M], block_shape[M-1],
// 
//       input_shape[M+1], ..., input_shape[N-1]]
// 
// 3. Reshape `permuted` to produce `reshaped_permuted` of shape
//      [batch / prod(block_shape),
// 
//       input_shape[1] * block_shape[0],
//       ...,
//       input_shape[M] * block_shape[M-1],
// 
//       input_shape[M+1],
//       ...,
//       input_shape[N-1]]
// 
// 4. Crop the start and end of dimensions `[1, ..., M]` of
//    `reshaped_permuted` according to `crops` to produce the output of shape:
//      [batch / prod(block_shape),
// 
//       input_shape[1] * block_shape[0] - crops[0,0] - crops[0,1],
//       ...,
//       input_shape[M] * block_shape[M-1] - crops[M-1,0] - crops[M-1,1],
// 
//       input_shape[M+1], ..., input_shape[N-1]]
// 
// Some examples:
// 
// (1) For the following input of shape `[4, 1, 1, 1]`, `block_shape = [2, 2]`, and
//     `crops = [[0, 0], [0, 0]]`:
// 
// ```prettyprint
// [[[[1]]], [[[2]]], [[[3]]], [[[4]]]]
// ```
// 
// The output tensor has shape `[1, 2, 2, 1]` and value:
// 
// ```prettyprint
// x = [[[[1], [2]], [[3], [4]]]]
// ```
// 
// (2) For the following input of shape `[4, 1, 1, 3]`, `block_shape = [2, 2]`, and
//     `crops = [[0, 0], [0, 0]]`:
// 
// ```prettyprint
// [[[1, 2, 3]], [[4, 5, 6]], [[7, 8, 9]], [[10, 11, 12]]]
// ```
// 
// The output tensor has shape `[1, 2, 2, 3]` and value:
// 
// ```prettyprint
// x = [[[[1, 2, 3], [4, 5, 6]],
//       [[7, 8, 9], [10, 11, 12]]]]
// ```
// 
// (3) For the following input of shape `[4, 2, 2, 1]`, `block_shape = [2, 2]`, and
//     `crops = [[0, 0], [0, 0]]`:
// 
// ```prettyprint
// x = [[[[1], [3]], [[9], [11]]],
//      [[[2], [4]], [[10], [12]]],
//      [[[5], [7]], [[13], [15]]],
//      [[[6], [8]], [[14], [16]]]]
// ```
// 
// The output tensor has shape `[1, 4, 4, 1]` and value:
// 
// ```prettyprint
// x = [[[1],   [2],  [3],  [4]],
//      [[5],   [6],  [7],  [8]],
//      [[9],  [10], [11],  [12]],
//      [[13], [14], [15],  [16]]]
// ```
// 
// (4) For the following input of shape `[8, 1, 3, 1]`, `block_shape = [2, 2]`, and
//     `crops = [[0, 0], [2, 0]]`:
// 
// ```prettyprint
// x = [[[[0], [1], [3]]], [[[0], [9], [11]]],
//      [[[0], [2], [4]]], [[[0], [10], [12]]],
//      [[[0], [5], [7]]], [[[0], [13], [15]]],
//      [[[0], [6], [8]]], [[[0], [14], [16]]]]
// ```
// 
// The output tensor has shape `[2, 2, 4, 1]` and value:
// 
// ```prettyprint
// x = [[[[1],   [2],  [3],  [4]],
//       [[5],   [6],  [7],  [8]]],
//      [[[9],  [10], [11],  [12]],
//       [[13], [14], [15],  [16]]]]
// ```
func BatchToSpaceND(scope *Scope, input tf.Output, block_shape tf.Output, crops tf.Output)(output tf.Output) {
	if scope.Err() != nil {
		return
	}
	opspec := tf.OpSpec{
		Type: "BatchToSpaceND",
		Input: []tf.Input{
			input, block_shape, crops, 
		},
	}
	op := scope.AddOperation(opspec)
	return op.Output(0)
}

// SpaceToBatch for N-D tensors of type T.
//
// This operation divides "spatial" dimensions `[1, ..., M]` of the input into a
// grid of blocks of shape `block_shape`, and interleaves these blocks with the
// "batch" dimension (0) such that in the output, the spatial dimensions
// `[1, ..., M]` correspond to the position within the grid, and the batch
// dimension combines both the position within a spatial block and the original
// batch position.  Prior to division into blocks, the spatial dimensions of the
// input are optionally zero padded according to `paddings`.  See below for a
// precise description.
//
// Arguments:
//	input: N-D with shape `input_shape = [batch] + spatial_shape + remaining_shape`,
// where spatial_shape has `M` dimensions.
//	block_shape: 1-D with shape `[M]`, all values must be >= 1.
//	paddings: 2-D with shape `[M, 2]`, all values must be >= 0.
//   `paddings[i] = [pad_start, pad_end]` specifies the padding for input dimension
//   `i + 1`, which corresponds to spatial dimension `i`.  It is required that
//   `block_shape[i]` divides `input_shape[i + 1] + pad_start + pad_end`.
// 
// This operation is equivalent to the following steps:
// 
// 1. Zero-pad the start and end of dimensions `[1, ..., M]` of the
//    input according to `paddings` to produce `padded` of shape `padded_shape`.
// 
// 2. Reshape `padded` to `reshaped_padded` of shape:
// 
//      [batch] +
//      [padded_shape[1] / block_shape[0],
//        block_shape[0],
//       ...,
//       padded_shape[M] / block_shape[M-1],
//       block_shape[M-1]] +
//      remaining_shape
// 
// 3. Permute dimensions of `reshaped_padded` to produce
//    `permuted_reshaped_padded` of shape:
// 
//      block_shape +
//      [batch] +
//      [padded_shape[1] / block_shape[0],
//       ...,
//       padded_shape[M] / block_shape[M-1]] +
//      remaining_shape
// 
// 4. Reshape `permuted_reshaped_padded` to flatten `block_shape` into the batch
//    dimension, producing an output tensor of shape:
// 
//      [batch * prod(block_shape)] +
//      [padded_shape[1] / block_shape[0],
//       ...,
//       padded_shape[M] / block_shape[M-1]] +
//      remaining_shape
// 
// Some examples:
// 
// (1) For the following input of shape `[1, 2, 2, 1]`, `block_shape = [2, 2]`, and
//     `paddings = [[0, 0], [0, 0]]`:
// 
// ```prettyprint
// x = [[[[1], [2]], [[3], [4]]]]
// ```
// 
// The output tensor has shape `[4, 1, 1, 1]` and value:
// 
// ```prettyprint
// [[[[1]]], [[[2]]], [[[3]]], [[[4]]]]
// ```
// 
// (2) For the following input of shape `[1, 2, 2, 3]`, `block_shape = [2, 2]`, and
//     `paddings = [[0, 0], [0, 0]]`:
// 
// ```prettyprint
// x = [[[[1, 2, 3], [4, 5, 6]],
//       [[7, 8, 9], [10, 11, 12]]]]
// ```
// 
// The output tensor has shape `[4, 1, 1, 3]` and value:
// 
// ```prettyprint
// [[[1, 2, 3]], [[4, 5, 6]], [[7, 8, 9]], [[10, 11, 12]]]
// ```
// 
// (3) For the following input of shape `[1, 4, 4, 1]`, `block_shape = [2, 2]`, and
//     `paddings = [[0, 0], [0, 0]]`:
// 
// ```prettyprint
// x = [[[[1],   [2],  [3],  [4]],
//       [[5],   [6],  [7],  [8]],
//       [[9],  [10], [11],  [12]],
//       [[13], [14], [15],  [16]]]]
// ```
// 
// The output tensor has shape `[4, 2, 2, 1]` and value:
// 
// ```prettyprint
// x = [[[[1], [3]], [[9], [11]]],
//      [[[2], [4]], [[10], [12]]],
//      [[[5], [7]], [[13], [15]]],
//      [[[6], [8]], [[14], [16]]]]
// ```
// 
// (4) For the following input of shape `[2, 2, 4, 1]`, block_shape = `[2, 2]`, and
//     paddings = `[[0, 0], [2, 0]]`:
// 
// ```prettyprint
// x = [[[[1],   [2],  [3],  [4]],
//       [[5],   [6],  [7],  [8]]],
//      [[[9],  [10], [11],  [12]],
//       [[13], [14], [15],  [16]]]]
// ```
// 
// The output tensor has shape `[8, 1, 3, 1]` and value:
// 
// ```prettyprint
// x = [[[[0], [1], [3]]], [[[0], [9], [11]]],
//      [[[0], [2], [4]]], [[[0], [10], [12]]],
//      [[[0], [5], [7]]], [[[0], [13], [15]]],
//      [[[0], [6], [8]]], [[[0], [14], [16]]]]
// ```
// 
// Among others, this operation is useful for reducing atrous convolution into
// regular convolution.
func SpaceToBatchND(scope *Scope, input tf.Output, block_shape tf.Output, paddings tf.Output)(output tf.Output) {
	if scope.Err() != nil {
		return
	}
	opspec := tf.OpSpec{
		Type: "SpaceToBatchND",
		Input: []tf.Input{
			input, block_shape, paddings, 
		},
	}
	op := scope.AddOperation(opspec)
	return op.Output(0)
}

// Generates values in an interval.
//
// A sequence of `num` evenly-spaced values are generated beginning at `start`.
// If `num > 1`, the values in the sequence increase by `stop - start / num - 1`,
// so that the last one is exactly `stop`.
// 
// For example:
// 
// ```
// tf.linspace(10.0, 12.0, 3, name="linspace") => [ 10.0  11.0  12.0]
// ```
//
// Arguments:
//	start: First entry in the range.
//	stop: Last entry in the range.
//	num: Number of values to generate.
//
// Returns 1-D. The generated values.
func LinSpace(scope *Scope, start tf.Output, stop tf.Output, num tf.Output)(output tf.Output) {
	if scope.Err() != nil {
		return
	}
	opspec := tf.OpSpec{
		Type: "LinSpace",
		Input: []tf.Input{
			start, stop, num, 
		},
	}
	op := scope.AddOperation(opspec)
	return op.Output(0)
}
